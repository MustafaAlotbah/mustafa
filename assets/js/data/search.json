[
  
  {
    "title": "C++20 - Coroutines",
    "url": "/posts/CPP-Coroutines/",
    "categories": "Software-Development, C++",
    "tags": "Software, C++, C++20, Software, Designs, Generator, Coroutine",
    "date": "2024-01-22 21:34:00 +0100",
    





    
    "snippet": "Coroutines, introduced in C++20, bring a powerful mechanism for handling asynchronous operations, generators and cooperative multitasking.Unlike conventional functions, which execute sequentially f...",
    "content": "Coroutines, introduced in C++20, bring a powerful mechanism for handling asynchronous operations, generators and cooperative multitasking.Unlike conventional functions, which execute sequentially from start to return, coroutines are functions that can suspend and resume execution at specific points, effectively allowing you to pause execution, yield results, and return control to the caller without fully exiting the function.IntroductionAt their core, coroutines empower cooperative multitasking by enabling a function to be suspended and later resumed without losing its state.This is in contrast to preemptive multitasking—such as that implemented with threads—where the operating system arbitrarily decides when to suspend a task and switch context.Coroutines, by contrast, give the programmer explicit control over when and where to suspend or resume execution, making them a lighter and more efficient alternative for certain asynchronous programming patterns.When a coroutine is called, it doesn’t run to completion immediately. Instead, it returns a special object, typically referred to as a coroutine handle, which the caller can use to resume or finalize the coroutine’s execution. This behavior introduces a level of flexibility and control that traditional functions simply do not possess.Coroutines can be applied across a wide range of use cases, including:      Asynchronous I/O:    Efficiently suspending operations until data becomes available from a network or file system, avoiding costly thread blocking.        Event-driven systems:    Enabling highly responsive applications by reacting to incoming events without halting the system, while simultaneously maintaining clarity in control flow.        Lazy data generation:    Producing data incrementally, without needing to allocate or compute the entire sequence at once, thus optimizing memory and computation resources.  ObjectiveIn this article, we will implement a simple generator-like coroutine that produces a sequence of integers, yielding values incrementally as they are requested. Consider the following example:int main() {    // Create the coroutine to count from 1 to 5    Generator counter = simple_counter(1, 5);      // Iterate through the yielded values    while (counter.next()) {        // Output each yielded value        std::cout &lt;&lt; counter.get() &lt;&lt; \" \";      }    std::cout &lt;&lt; std::endl;    return 0;}The expected output for this program would be:1 2 3 4 5The primary coroutine function we aim to implement is a generator that yields consecutive integers between a given start and end value:// Coroutine function that yields consecutive numbersGenerator simple_counter(int start, int end) {    for (int i = start; i &lt;= end; ++i) {        // yield the current value        co_yield i;    }}In the code above, co_yield is the key operator introduced by C++20 coroutines. When encountered, it pauses the execution of the coroutine and returns a value to the caller. The coroutine can then be resumed from this point, maintaining the state of local variables.Let’s break down the essential components involved in making this coroutine functional and efficient in C++20.Formal DefinitionIn C++20, coroutines are implemented under the hood as a finite state machine (FSM)—a widely-recognized computational model where the system resides in one of a finite number of states at any given time and transitions between states occur based on events. For coroutines, these transitions involve saving the current state of execution and potentially performing actions such as yielding a value or suspending execution. This FSM model is particularly well-suited for coroutines, as they are designed to pause, yield results, and resume at precise points during their execution.A coroutine’s state persists across suspension points, enabling the function to resume from exactly where it was last paused upon the next invocation. Control over these state transitions in C++20 coroutines is achieved through three key operations:      co_yield:    The co_yield operator suspends the coroutine while yielding a value back to the caller. It also allows a coroutine to generate a sequence of values over multiple suspensions, maintaining its state between yields. This makes it highly suitable for generator-style coroutines, where values are produced incrementally.        co_return:    The co_return statement signals the completion of the coroutine, returning a final value. Once a coroutine encounters co_return, it cannot be resumed, and the coroutine’s lifetime ends.        co_await:    The co_await operator suspends the coroutine, handing control back to the caller, until a specific condition—typically represented as an asynchronous event—is met. When the awaited condition is fulfilled, the coroutine resumes execution at the point where it was suspended. The type of object that is awaited must conform to the Awaitable concept, which means it must provide the following methods:          await_ready(): Determines if the operation is ready to proceed or if it needs to suspend.      await_suspend(): Suspends the coroutine and potentially schedules it to be resumed later.            await_resume(): Returns the result of the awaited operation when the coroutine is resumed.  State Transitions in CoroutinesThe execution of a coroutine is driven by state transitions, which are managed by the co_await, co_yield, and co_return operations. These transitions occur between the following states:      Initial State: When a coroutine is first called, it enters the initial state. At this point, the function promise_type::initial_suspend() decides whether the coroutine should immediately suspend or continue execution. This gives the developer control over whether the coroutine begins running immediately or waits to be explicitly resumed.        Running State: Once execution begins, the coroutine proceeds normally until it encounters a suspension point, such as a co_await or co_yield. Upon reaching these points, it returns control to the caller and moves into the suspended state.        Suspended State: While suspended, the coroutine’s execution context—including its local variables and call stack—is preserved. At any point, the coroutine can be resumed, at which point it continues execution from the last suspension point, progressing toward its next suspension or completion.        Final State: After the coroutine encounters a co_return, it enters the final state, indicating the completion of its execution. The function promise_type::final_suspend() ensures that no further actions can be taken on the coroutine once it has reached this point, allowing for proper cleanup and termination.  These operations and state transitions make it easier to manage asynchronous workflows, allowing for clear and efficient state management while maintaining a straightforward control flow. By combining these with custom promise_type objects and awaitable objects, C++20 coroutines offer a powerful abstraction for managing both synchronous and asynchronous tasks.Lifecycle of a CoroutineThe lifecycle of a coroutine is intricately managed by these state transitions. The following diagram captures the transitions and operations:stateDiagram-v2    %% Starting point    [*] --&gt; InitialState    InitialState: Initial State    %% Transition to Running or Suspended State based on initial_suspend()    InitialState --&gt; RunningState: coroutine called    InitialState --&gt; SuspendedState: initial_suspend()    %% Running State    RunningState: Running State    RunningState --&gt; SuspendedState: co_await / co_yield    RunningState --&gt; FinalState: co_return    %% Suspended State    SuspendedState: Suspended State    SuspendedState --&gt; RunningState: resume()    SuspendedState --&gt; FinalState: co_return / Scope End    %% Final State    FinalState: Final State    FinalState: final_suspend()By explicitly controlling state transitions, C++20 coroutines provide a structured, efficient mechanism for managing asynchronous workflows. Unlike traditional multithreading, where the operating system handles preemptive task switching, coroutines give the programmer direct control over suspensions and resumptions, leading to a more predictable and performant system. Moreover, the use of promise_type and awaitable objects allows developers to customize the behavior of coroutines, providing fine-grained control over both synchronous and asynchronous tasks.Implementing the CoroutineIn order to employ the co_yield operator within a function, the return type must conform to the coroutine concept as defined by the C++20 standard. When the compiler detects the presence of keywords like co_yield, co_await, or co_return, it automatically flags the function as a coroutine, which fundamentally changes its behavior.Instead of following the conventional function model of entering, executing, and exiting, coroutines return an intermediate object (e.g. Generator) that encapsulates their state and enables suspension and resumption of execution. This returned object serves as the interface through which the coroutine interacts with the calling environment.In our example, the coroutine will return an object of type Generator, which will function as a generator of integers. To fulfill the coroutine’s requirements and the compiler’s expectations, we need to define a corresponding generator class, Generator, that adheres to the coroutine concept. At the core of this concept lies the promise_type, a structure that mediates between the caller and the coroutine, orchestrating the coroutine’s lifecycle, including suspension, resumption, and finalization.Below is the skeletal structure of our generator Generator, which we will expand to implement the necessary coroutine mechanisms:class Generator {    // Required by the compiler to control the coroutine    struct promise_type;      // constructor    Generator(std::coroutine_handle&lt;promise_type&gt; handle);   private:     // Handle to control coroutine execution    std::coroutine_handle&lt;promise_type&gt; coroutine_handle_; }The Heart of Coroutines: promise_typeThe promise_type structure is the core component in C++20 coroutines, responsible for managing the coroutine’s internal state and interacting with the calling code. Whenever a coroutine is invoked, the compiler generates an instance of the promise_type. The promise_type interface defines how the coroutine behaves at each phase of its execution, including initial suspension, resumption, final suspension, and error handling.The promise_type must provide the following methods to manage coroutine state transitions:struct promise_type {    // Returns the object that the coroutine will hand back to the caller    Generator get_return_object();    // Suspend execution immediately after starting    std::suspend_always initial_suspend();    // Suspend execution after the coroutine is done    std::suspend_always final_suspend() noexcept;    // Handle any exceptions that occur within the coroutine    void unhandled_exception();};Key methods that must be implemented in promise_type include:            Generator get_return_object():  This method returns the object that will represent the coroutine’s execution state to the caller. It is called as soon as the coroutine is instantiated. In the case of a generator, it returns a handle to the coroutine itself, allowing the caller to resume or query the coroutine’s state.        The typical implementation for this method is as follows:      Generator Generator::promise_type::get_return_object()    {      // The coroutine_handle manages the lifetime and resumption of the coroutine      return Generator{std::coroutine_handle&lt;promise_type&gt;::from_promise(*this)};    }    Here, the from_promise() function creates a coroutine handle that ties the promise_type to the coroutine object, providing the caller with full control over the coroutine’s lifecycle.        std::suspend_always initial_suspend():  This method determines whether the coroutine should suspend execution immediately upon creation. The return type must satisfy the awaitable concept, which determines how the coroutine behaves at suspension points. Returning std::suspend_always ensures that the coroutine will suspend after being invoked, giving the caller control over when to resume execution.    Example implementation:      std::suspend_always Generator::promise_type::initial_suspend()    {        // The coroutine starts in a suspended state and must be resumed explicitly      return {};    }    In this case, we return std::suspend_always, indicating that the coroutine suspends right after its invocation, awaiting an explicit resume action.        std::suspend_always final_suspend():  This method is called when the coroutine reaches its end, either through a co_return or because the function runs to completion. It determines whether the coroutine should suspend before final cleanup or exit immediately. The typical pattern is to use std::suspend_always to ensure that the caller has an opportunity to finalize any resources tied to the coroutine handle.    Example:      std::suspend_always Generator::promise_type::final_suspend()    {        // After the coroutine is done, it suspends one last time before being destroyed      return {};    }    This final suspension is a key point in the coroutine’s lifecycle, giving the caller a chance to perform any necessary cleanup or synchronizing actions.        void unhandled_exception()    This method defines the coroutine’s behavior when an exception is thrown inside the coroutine body and not explicitly handled. The most common implementation involves terminating the program, but more advanced handlers could log the error or propagate the exception to the caller.    Example implementation:      void Generator::promise_type::unhandled_exception()    {        // Terminate the program or just log an error and freeze the coroutine      std::terminate();    }    In this basic implementation, std::terminate() is called to halt the program when an unhandled exception occurs within the coroutine. More advanced coroutine systems may instead propagate exceptions back to the caller.  The Awaitable ConceptThe awaitable concept in C++ defines a set of rules for objects that can be used in conjunction with co_await. These objects determine whether a coroutine should suspend, what happens when it suspends, and how the coroutine resumes. In the context of coroutines, both std::suspend_always and std::suspend_never are common awaitables that provide predefined behavior for suspension.      std::suspend_always:  This is an awaitable that always suspends the coroutine. It is used when the coroutine should explicitly suspend, allowing the caller to determine when to resume it.      struct std::suspend_always {      bool await_ready() const noexcept { return false; }      void await_suspend(std::coroutine_handle&lt;&gt;) const noexcept {}      void await_resume() const noexcept {}  };          await_ready(): Returns false, indicating that the coroutine should suspend.      await_suspend(): Performs the actual suspension.      await_resume(): Defines what happens when the coroutine resumes.            std::suspend_never:  This awaitable ensures that the coroutine never suspends at a particular suspension point, allowing it to continue execution without interruption.      struct std::suspend_never {      bool await_ready() const noexcept { return true; }      void await_suspend(std::coroutine_handle&lt;&gt;) const noexcept {}      void await_resume() const noexcept {}  };          await_ready(): Returns true, meaning the coroutine does not suspend.      await_suspend() and await_resume() are no-ops, as no suspension occurs.      Coroutine OperatorsIn C++20, coroutines utilize specialized operators (co_await, co_yield, and co_return) to manage control flow, yielding values, awaiting asynchronous events, or signaling coroutine completion. For a coroutine to function correctly, it must overload and implement at least one of these operators. The choice of the operator depends on the desired behavior—whether the coroutine should suspend while awaiting, yield intermediate results, or complete execution and return a value.The Operator co_yieldThe co_yield operator facilitates the suspension of the coroutine, returning control to the caller while also passing back a value.To overload this operator, the promise_type structure must implement at least one of two forms of yield_value:  awaitable yield_value(T) or awaitable yield_void().struct promise_type {    Generator get_return_object();    std::suspend_always initial_suspend();    std::suspend_always final_suspend() noexcept;    void unhandled_exception();    // Overload for yielding an integer value (e.g., `co_yield 5;`)    std::suspend_always yield_value(int val);    // Overload for yielding a string value (e.g., `co_yield \"Hello\";`)    std::suspend_always yield_value(std::string val);    // Yielding control without passing a value (e.g., `co_yield;`)    std::suspend_always yield_void();};In the context of a generator design like Generator, the yield_value function is used to store or update the coroutine’s internal state (current_value), which the user can later retrieve. However, coroutines are much more powerful and can solve more complex control flow problems than simple generators.      awaitable yield_value(T):    This method is invoked when co_yield is used in the coroutine. It suspends the coroutine and yields the value T to the caller. At this suspension point, the state of the coroutine is preserved, allowing it to resume at a later time. The caller can retrieve the yielded value after resumption.    Example implementation:      std::suspend_always promise_type::yield_value(int value) {      value_ = value;  // Store the yielded value in the internal state      return {};       // Suspend the coroutine  }        awaitable yield_void():    This method is called when the coroutine is suspended without yielding a specific value to the caller. It can be used when the coroutine needs to pause execution but doesn’t produce an output. This operator is less common in generator-style coroutines but can be useful in control flow scenarios.    Example:      std::suspend_always promise_type::yield_void() {      // Suspend the coroutine without yielding a value      return {};  }  Hence for our Generator example, we could defineclass Generator  {   public:    struct promise_type      {      public:          Generator get_return_object();          std::suspend_always initial_suspend();          std::suspend_always final_suspend() noexcept;           void unhandled_exception();              // Overload co_yield,         std::suspend_always yield_value(int val);     public:        friend class Generator;        int value_{ 0 };      };    // type alias to reduce code    using handle_type = std::coroutine_handle&lt;promise_type&gt;;  private:    handle_type coroutine_handle_;}The Operator co_returnThe co_return operator signals the end of a coroutine and allows the coroutine to return a value to the caller. The promise_type must implement return_value(T) or return_void() to overload this operator.Example:struct promise_type {    Generator get_return_object();    std::suspend_always initial_suspend();    std::suspend_always final_suspend() noexcept;    void unhandled_exception();    // Return an integer value upon coroutine completion (e.g., `co_return 42;`)    std::suspend_always return_value(int val);    // Return a string upon coroutine completion (e.g., `co_return \"Done\";`)    std::suspend_always return_value(std::string val);    // Signal coroutine completion without returning a value (e.g., `co_return;`)    std::suspend_always return_void();};In the Generator example, we could overload the return_value and return_void operators to handle final results or simply to indicate that the coroutine has completed its execution.      awaitable return_value(T):    This method is called when co_return is used in the coroutine, allowing the coroutine to return a final value to the caller. It suspends the coroutine, signals completion, and passes the return value back to the caller.      std::suspend_always Generator::promise_type::return_value(int val) {      value_ = val;  // Store the final returned value      return {};     // Suspend the coroutine before finalization  }    In this example, the return_value method stores the value passed to co_return in the value_ field of the promise_type. The coroutine is then suspended one last time, allowing the caller to retrieve the value before the coroutine is destroyed.    Usage in a coroutine:      Generator simple_counter(int start, int end) {      for (int i = start; i &lt;= end; ++i) {          co_yield i;      }      // Return a final result after the loop completes      co_return end + 1;    }        awaitable return_void():    This method is invoked when co_return is used without a value, simply marking the coroutine as complete and suspending it for final cleanup. This is useful when the coroutine’s task is done, and no final value needs to be returned. After calling return_void(), the coroutine transitions to its final suspended state and is then cleaned up.      std::suspend_always promise_type::yield_void() {      // Suspend the coroutine without yielding a value      return {};  }    In this case, the coroutine finishes without yielding or returning any specific value. The final suspension allows the coroutine’s resources to be cleaned up in an orderly fashion.    Usage in a coroutine:      Generator simple_counter(int start, int end) {      for (int i = start; i &lt;= end; ++i) {          co_yield i;      }      // End the coroutine without returning a value      co_return;  }  Managing the Coroutine HandleIn the above implementation, we leverage std::coroutine_handle to manage the lifecycle of the coroutine. This handle acts as a lightweight wrapper that directly interfaces with the coroutine, allowing control over its execution. The handle is essential for interacting with the coroutine at various stages—suspension, resumption, finalization, and cleanup.Here is a more detailed explanation of the key functions of std::coroutine_handle utilized in our Generator example:      void destroy(): The destroy() method is used to explicitly destroy the coroutine. It ensures that once the coroutine has completed its execution, its resources are properly cleaned up, preventing memory leaks. In our Generator class, we call destroy() within the destructor, ensuring that if the coroutine is still alive, it gets terminated and cleaned up before the Generator object goes out of scope.    Example usage in the destructor:     Generator::~Generator() {     // Clean up coroutine resources     if (coroutine_handle_) coroutine_handle_.destroy();   }        void resume(): The resume() method allows the coroutine to proceed from its last suspension point. This is used within the next() function, which resumes the coroutine and attempts to move it to the next co_yield or co_return. By invoking resume(), the coroutine’s execution is continued until it either reaches another suspension point or completes execution.        bool done(): The done() method checks whether the coroutine has reached its final state and is no longer resumable. It returns true if the coroutine has completed execution. This is important for ensuring that the coroutine is not resumed after it has finished. In the next() function, done() is checked both before and after calling resume() to ensure that the coroutine is still active.        promise_type&amp; promise(): The promise() method provides access to the promise_type instance associated with the coroutine. This is crucial because the promise_type holds the internal state of the coroutine, including the value that was last yielded or returned. The promise() method is used in the get() function to retrieve the current value yielded by the coroutine.  Retrieving Values in the GeneratorTo allow interaction between the Generator generator and the caller, we need two essential methods:      bool next(): This method continues the execution of the coroutine until it suspends again, either due to a co_yield or co_return. It checks if the coroutine is done, resumes execution, and returns whether the coroutine has yielded a new value. If the coroutine has completed execution, it returns false.    Full implementation:      bool Generator::next() const    {       if (!coroutine_handle_ || coroutine_handle_.done()) return false;       // Resume the coroutine       coroutine_handle_.resume();       // Check again if it's done after resuming       return !coroutine_handle_.done();  }    Before resuming the coroutine, we first ensure that the coroutine handle is properly initialized and that the coroutine has not already completed its execution. This is accomplished by checking if the handle is valid and if the coroutine is not in the done state.    Once confirmed, we can safely invoke the resume() method to move the coroutine forward to its next suspension point. The use of co_yield within the coroutine may return a value and suspend execution at multiple points before the function fully completes. After calling resume(), it is essential to check again whether the coroutine has reached its final state by invoking done().    If the resumption of the coroutine leads to its termination without yielding any additional values, we return false, indicating that the coroutine has completed its task. This prevents further attempts to resume a completed coroutine.    However, if we employ co_return at the end of the coroutine, and it results in a final value being returned, we would return true, as this indicates that the coroutine has successfully yielded a value before reaching its conclusion. In this case, the caller can retrieve the final value using the get() method.        int get(): This method retrieves the current value yielded by the coroutine. It accesses the promise_type through the coroutine handle to fetch the stored value. This method should be called after next() returns true, indicating that the coroutine has successfully yielded a new value.  Full implementation:      int Generator::get() const    {        return coroutine_handle_.promise().value_;    }    Here, the method accesses the promise_type instance via the coroutine_handle_, fetching the value_ field, which stores the value yielded during the last co_yield or co_return.  "
  },
  
  {
    "title": "Efficient Exception Handling in Resource-Constrained Embedded Systems",
    "url": "/posts/Exploring-Exception-Handling-Mechanisms-in-Embedded-Environments/",
    "categories": "Embedded-Development, Software-Designs, Error, Handling",
    "tags": "Embedded, STM32, Error-Handling, Exception-Handling, Resource Optimization, setjmp, jump, goto, longjump, Low-Level Programming, ARM, C++",
    "date": "2023-12-22 12:41:00 +0100",
    





    
    "snippet": "IntroductionThis article provides a comprehensive analysis of exception handling mechanisms specifically designed for embedded systems, where resource constraints and performance optimization are p...",
    "content": "IntroductionThis article provides a comprehensive analysis of exception handling mechanisms specifically designed for embedded systems, where resource constraints and performance optimization are paramount. In such environments, traditional C++ exception handling is often deemed impractical due to the substantial overhead it incurs. Consequently, developers frequently resort to disabling exceptions using compiler flags such as -fno-exceptions. Despite this, the necessity for robust error management remains critical, especially in scenarios where system stability must be preserved in the face of unexpected errors.To address these challenges, this article explores a range of alternative error-handling strategies that are more suitable for embedded systems. The discussion begins with low-level constructs such as goto statements and function pointers, which provide direct and efficient methods for error management. It then advances to more sophisticated techniques involving setjmp and longjmp, which enable the simulation of exception handling with minimal resource consumption. Through detailed and practical examples, we illustrate how these methods can be effectively implemented in resource-constrained environments, ensuring that errors are managed gracefully without compromising system performance.In addition to these low-level approaches, the article also examines modern C++ techniques that offer lightweight alternatives to traditional exceptions. Constructs like std::optional and std::variant provide structured and efficient methods for error handling, allowing for more granular and type-safe error management with minimal overhead. These modern techniques are particularly advantageous in embedded systems where performance and memory efficiency are critical.Furthermore, the article addresses the complexities introduced by these alternative methods, particularly concerning resource management and cleanup. Practical solutions are presented to prevent issues such as memory leaks, which are essential for ensuring the long-term reliability of embedded systems. By the conclusion of this article, readers will have gained a thorough understanding of how to implement robust and efficient error-handling mechanisms, leveraging both traditional and modern C++ approaches. This knowledge is vital for enhancing the reliability and sustainability of mission-critical applications in embedded environments.Understanding setjmp and longjmpLow-Level Error Handling: A Pragmatic ApproachBefore exploring advanced error-handling constructs like setjmp and longjmp, it is instructive to examine a fundamental, low-level approach to error management using function pointers and the goto statement. This method operates closer to the hardware, offering a highly efficient solution in embedded contexts where minimizing computational overhead is essential.Consider the following code snippet, which demonstrates this approach:#include &lt;iostream&gt;// environmentvoid* try_block = nullptr;volatile int errorCode = 0;void riskyFunction() {    // Simulate the effect of longjmp    std::cout &lt;&lt; \"Starting a risky function.\\n\";        // Mimic throwing an exception (error code: 1)    if (try_block) {        errorCode = 1;        // Simulate setting an error code        goto *try_block;      // Jump back to the try block    }    std::cout &lt;&lt; \"No errors detected.\\n\";}int main() {    // Save the address of the try block    try_block = &amp;&amp;try_block_label;try_block_label:    if (errorCode == 0) {        riskyFunction();    } else {        std::cout &lt;&lt; \"An error occurred!\\n\";    }    return 0;}The output:&gt;&gt;&gt;Starting a risky function.An error occurred!      void* try_block:    This pointer stores the address of a specific code location, effectively serving as a jump target.        volatile int errorCode:    This global variable indicates whether an error has occurred. The volatile qualifier ensures that the variable’s value is always read directly from memory, which is crucial in environments where memory consistency is a concern.        riskyFunction:    This function simulates a risky operation. If an error is detected, the function jumps back to the location pointed to by try_block, updating the errorCode to signal the error.        goto:    The goto statement allows the program to jump back to the try_block_label if an error is detected, thereby simulating a rudimentary exception handling mechanism.  While this approach is relatively straightforward, it can be effective in highly constrained environments where even the overhead of setjmp and longjmp might be undesirable. However, it is less flexible and more prone to errors compared to higher-level constructs.Advanced Error Handling: Leveraging setjmp and longjmpFor scenarios that demand a higher level of abstraction and control, setjmp and longjmp offer a powerful mechanism to save and restore the program’s execution context. The setjmp function captures the current environment—including the stack context and registers—into a buffer (typically of type jmp_buf), while longjmp restores this environment, effectively reverting the program’s state to the point where setjmp was initially invoked.Consider the following implementation:#include &lt;iostream&gt;#include &lt;csetjmp&gt;jmp_buf environment;void riskyFunction() {    if (/* some error condition */) {        // Simulates throw Error(code=1)        longjmp(environment, 1);    }    std::cout &lt;&lt; \"No errors detected.\\n\";}int main() {    int errorCode = setjmp(environment);    if (errorCode == 0) {        // Simulates Try block        riskyFunction();    } else {        // Simulates Catch block        std::cout &lt;&lt; \"An error occurred!\\n\";    }    return 0;}This example illustrates the practical utility of setjmp and longjmp in managing control flow amidst errors—a particularly valuable capability in embedded systems where traditional exception handling is not feasible.Handling Typed Exceptions with setjmp and longjmpThe conceptual framework provided by setjmp and longjmp can be extended to handle multiple error types, each requiring a distinct response. This approach allows developers to implement typed exceptions, even in environments where conventional C++ exceptions are unavailable.#include &lt;iostream&gt;#include &lt;csetjmp&gt;jmp_buf environment;int constexpr ValueException  = 1;int constexpr SyntaxException = 2;void riskyFunction() {    if (/* some error condition for value correctness*/) {        // Simulates throw ValueException;        longjmp(environment, ValueException);    }        if (/* some error condition for syntax correctness*/) {        // Simulates throw SyntaxException;        longjmp(environment, SyntaxException);    }    std::cout &lt;&lt; \"No errors detected.\\n\";}int main() {    int errorCode = setjmp(environment);    if (errorCode == 0) {            // Simulates Try block        riskyFunction();            } else if (errorCode == ValueException) {            // Handle Value Error        std::cout &lt;&lt; \"ValueException ocurred\\n\";            } else if (errorCode == SyntaxException) {            // Handle Syntax Error        std::cout &lt;&lt; \"SyntaxException ocurred\\n\";            }    return 0;}This code demonstrates how longjmp can be employed to simulate typed exception handling, a practice commonly seen in state-based error handling within C. This approach not only enhances the robustness of error management but also introduces a level of granularity that aligns with the nuanced requirements of embedded systems.Exception Propagation: Implementing Exception CascadesIn more complex embedded applications, it is often necessary to propagate exceptions through multiple layers of function calls. The following example illustrates how longjmp can be utilized to create exception cascades, allowing errors to be propagated and handled at different levels of the program.#include &lt;iostream&gt;#include &lt;csetjmp&gt;jmp_buf environment;void riskyFunction() {    longjmp(environment, 1);}void secondFunction() {    longjmp(environment, 2);}int main() {    int errorCode = setjmp(environment);    if (errorCode == 0) {            // Calling a risky function        riskyFunction();            } else if (errorCode == 1) {            // Handling an error (which can also be handling)        std::cout &lt;&lt; \"riskyFunction called longjmp\\n\";        secondFunction();            } else if (errorCode == 2) {            // Exception was thrown while handling another exception        std::cout &lt;&lt; \"secondFunction called longjmp\\n\";            }    return 0;}This implementation showcases the flexibility of longjmp in orchestrating complex control flows within an embedded system. By allowing control to be transferred between disparate parts of the program, longjmp enables a more nuanced and responsive error-handling strategy, essential in high-stakes embedded applications.Simulating Exception Handling in Embedded Systems Using setjmp and longjmpDesigning a Basic Exception Handling FrameworkThe utility of setjmp and longjmp extends beyond simple error signaling; these functions can be taken advantage of to construct a rudimentary exception-handling framework that mimics the try-catch paradigm of higher-level programming languages. Such a framework is particularly advantageous in embedded systems where traditional C++ exceptions are either impractical or outright disabled.Practical Example: Integrating Resource Management with Exception HandlingIn embedded systems, resource management is a critical concern, especially given the limited availability of memory and processing power. The following example demonstrates how to implement a simple yet effective exception-handling mechanism that integrates resource management, ensuring that resources are properly released even in the presence of errors.Let’s define an ExceptionHandler class that replicates the behavior of try-catch blocks in a controlled embedded environment:class ExceptionHandler {public:    // Register Try block    ExceptionHandler&amp; Try(std::function&lt;void()&gt; func);    // Register Catch block    ExceptionHandler&amp; Catch(std::function&lt;void(int)&gt; func);    // Execute try/catch    void Execute();    // Reset the handler    void reset();    // throw an exception    void throwException(int error = 1);private:    bool                     isConfigured_ = false;    jmp_buf                  environment_;    std::function&lt;void()&gt;    tryBlock_;    std::function&lt;void(int)&gt; catchBlock_;};In this implementation, the Try and Catch methods serve as configuration functions that register their respective blocks of code:ExceptionHandler&amp; ExceptionHandler::Try(std::function&lt;void()&gt; func) {    tryBlock_     = func;    isConfigured_ = true;    return *this;}ExceptionHandler&amp; ExceptionHandler::Catch(std::function&lt;void(int)&gt; func) {    catchBlock_ = func;    return *this;}The throwException method triggers the exception handling by calling longjmp with the appropriate error code:void ExceptionHandler::throwException(int error) {    longjmp(env_, error);}The Execute method coordinates the execution of the Try and Catch blocks, managing control flow based on whether an exception has been thrown:  Setting up the jump environment.  Executing the Try block.  If an error occurs, executing the Catch block and passing the error code.  Resetting the handler for the next pair of try-catch blocks.void ExceptionHandler::Execute() {    // Ensure the Try and Catch blocks are properly configured    if (!isConfigured_)  return;        // Set up the environment for potential exceptions    int result = setjmp(env_);    if (result == 0) {        tryBlock_();    } else {        catchBlock_(result);    }    // Reset the handler state for future use    reset();}void ExceptionHandler::reset() {    tryBlock_     = nullptr;    catchBlock_   = nullptr;    isConfigured_ = false;}Here is an example of how this class might be used:int main() {    ExceptionHandler handler;    handler.Try([&amp;] {        // Try block        std::cout &lt;&lt; \"Try block: an error is about to occur.\\n\";        // Trigger an exception        handler.throwException(2);        std::cout &lt;&lt; \"This will not be printed.\\n\";    }).Catch([](int error) {            // Handle the exception in the Catch block        std::cout &lt;&lt; \"Catch block: caught error code \" &lt;&lt; error &lt;&lt; \"!\\n\";    }).Execute();    std::cout &lt;&lt; \"Program continues after try/catch.\\n\";    return 0;}The output of this program would be:&gt;&gt;&gt;Try block: an error is about to occur.Catch block: An exception was caught with error code (2)!Program continues after try/catch.C++ ResourcesOne of the strengths of C++ is its ability to automatically invoke the destructor of a class when it goes out of scope, whether the scope ends normally (by }) or through an exception. This ensures that resources are freed properly, even when they are allocated within nested functions. This feature, known as stack unwinding, is absent when using the goto keyword. A critical question arises: do we retain this feature when using longjmp?Cleaning Up with LongjmpThe answer is compiler-dependent. For instance, with the MSVC compiler, stack unwinding is supported with longjmp, as evidenced by the following statement: (see here)  In Microsoft C++ code on Windows, longjmp uses the same stack-unwinding semantics as exception-handling code. It’s safe to use in the same places that C++ exceptions can be raised.However, this would be assuming exception semantics are allowed, which is not the case in embedded environments.In GCC and ARM compilers, exception semantics are excluded from longjmp. To demonstrate this, consider a Resource class that tracks resource allocation and deallocation:class Resource {public:    Resource(const std::string&amp; name) : name_(name) {        std::cout &lt;&lt; name_ &lt;&lt; \" constructed!\\n\";    }    ~Resource() {        std::cout &lt;&lt; name_ &lt;&lt; \" destructed!\\n\";    }private:    std::string name_;};Now, let’s use this class as follows:// Global Exception HandlerExceptionHandler handler;int main() {    handler.Try([&amp;] {        // Try block        // This will not be destructed with throwException/longjmp        Resource res(\"MyResource\");         std::cout &lt;&lt; \"Try block: an error is about to occur.\\n\";        // Throw Exception        handler.throwException(2);        std::cout &lt;&lt; \"This will not be printed.\\n\";    }).Catch([](int error) {        // Catch an error        std::cout &lt;&lt; \"Catch block: caught error code (\" &lt;&lt; error &lt;&lt; \")!\\n\";    }).Execute();    std::cout &lt;&lt; \"Program continues after try/catch.\\n\";    return 0;}The output would be:&gt;&gt;&gt;MyResource constructed!Try block: an error is about to occur.Catch block: An exception was caught with error code (2)!Program continues after try/catch.As observed, the destructor for MyResource is not invoked, potentially leading to memory leaks—a serious concern in embedded systems.Manual Stack UnwindingTo address the previous issue, we can manually manage resource cleanup by extending the ExceptionHandler class:template &lt;typename T&gt;void registerCleanup(T&amp; resource){    cleanupStack_.emplace_back([&amp;resource](){      resource.~T();    });}The cleanupStack_ is a vector of destructor functions that are invoked when an exception is thrown:std::vector&lt;std::function&lt;void()&gt;&gt; cleanupStack_;When an exception is thrown, all registered variables are destructed:void ExceptionHandler::throwException(int error){    // Execute destructors first    for (auto it = cleanupStack_.rbegin(); it != cleanupStack_.rend(); ++it) (*it)();    cleanupStack_.clear();    // Then perform long jump    longjmp(env_, error);}This solution requires developers to manually register each local resource, as demonstrated below:// Global Exception HandlerExceptionHandler handler;void riskyFunction(){    // Resource    Resource localRes(\"ResourceInFunction\");    // Register the source before any exception might be thrown    handler.registerCleanup(localRes);    // Throw an exception    handler.throwException(4);    std::cout &lt;&lt; \"functionWithLocalResource: This line won't be executed if an exception is thrown.\\n\";}int main() {    handler.Try([&amp;] {        // Try block        // This will not be destructed with throwException/longjmp        Resource res(\"MyResource\");         // Register the source before any exception might be thrown        handler.registerCleanup(res);        std::cout &lt;&lt; \"Try block: an error is about to occur.\\n\";        // Call a risky function        riskyFunction(handler);        std::cout &lt;&lt; \"This will not be printed.\\n\";    }).Catch([](int error) {        // Catch an error        std::cout &lt;&lt; \"Catch block: caught error code (\" &lt;&lt; error &lt;&lt; \")!\\n\";    }).Execute();    std::cout &lt;&lt; \"Program continues after try/catch.\\n\";    return 0;}The output now reflects proper resource cleanup:&gt;&gt;&gt;MyResource constructed!ResourceInFunction constructed!ResourceInFunction destructed!MyResource destructed!Catch block: An exception was caught with error code (2)!Program continues after try/catch.Now, the destructors are invoked as expected. However, it is easy to overlook registering a local variable, which could lead to subtle bugs.Considerations for Embedded Systems: Balancing Complexity and EfficiencyWhile setjmp and longjmp offer a powerful means of simulating exception handling in embedded systems, they also introduce significant complexity, particularly in terms of managing the cleanup stack. This complexity is exacerbated in resource-constrained environments, where developers must meticulously balance performance, memory usage, and error handling. The manual cleanup required by GCC and ARM compilers adds another layer of difficulty, emphasizing the importance of thorough testing and validation to ensure system reliability.Alternative Approaches: Simplifying with gotoIn some embedded systems, simplicity and efficiency may outweigh the benefits of structured exception handling. In such cases, using the goto statement can provide a straightforward and pragmatic error-handling mechanism, albeit at the cost of abstraction and safety.#include &lt;iostream&gt;int riskyFunction() {    Resource localRes(\"ResourceInFunction\");    // Assume an error happened    int errorCode = doSomething(); // returns errorCode 4    // Check for an error    if (errorCode != 0) {        goto cleanup;    }    std::cout &lt;&lt; \"riskyFunction: This line won't be executed if an error occurs.\\n\";cleanup:    // Clean up resources if necessary    localRes.release();    // Return the error code    return errorCode;}int main() {    int errorCode = 0;    Resource res(\"MyResource\");    std::cout &lt;&lt; \"Try block: an error is about to occur.\\n\";    // Call the risky function and handle errors    errorCode = riskyFunction();    if (errorCode != 0) {        goto cleanup;    }    std::cout &lt;&lt; \"This will not be printed if an error occurs.\\n\";cleanup:    // Clean up resources    res.release();    if (errorCode != 0) {        std::cout &lt;&lt; \"Catch block: caught error code (\" &lt;&lt; errorCode &lt;&lt; \")!\\n\";    }    std::cout &lt;&lt; \"Program continues after try/catch.\\n\";    return errorCode;}Alternative Approaches: Modern C++Beyond the low-level techniques previously discussed, modern C++ introduces several lightweight alternatives to traditional exceptions that are particularly advantageous in resource-constrained embedded systems. These alternatives, including std::optional, std::variant, and error codes encapsulated within classes, offer a structured and efficient approach to error handling. Their minimal overhead makes them well-suited for environments where performance and memory efficiency are paramount.Utilizing std::optional for Error HandlingThe std::optional type, introduced in C++17, encapsulates an object that may or may not hold a value. This type is especially beneficial for functions that might fail to produce a meaningful result, allowing the function to return an “empty” state rather than throwing an exception or returning an error code.Example#include &lt;iostream&gt;  #include &lt;optional&gt;    std::optional&lt;int&gt; riskyFunction(int value) {       // Return an empty optional to indicate an error      if (value &lt; 0) return std::nullopt;        // Return the result as an optional      return value * 2;  }    int main() {      auto result = riskyFunction(-5);          // Handle the error    if (!result) {         std::cout &lt;&lt; \"An error occurred: invalid input.\\n\";         exit(0);  // Early termination    }        // Valid input, retrieve and display the value    std::cout &lt;&lt; \"Result: \" &lt;&lt; result.value() &lt;&lt; \"\\n\";          return 0;  }In this example, the function riskyFunction returns an std::optional&lt;int&gt;, which either contains a valid result or std::nullopt if an error occurs. This approach avoids the overhead of exceptions while providing a clear mechanism for error checking.Leveraging std::variant for Typed Errorsstd::variant, also introduced in C++17, is a type-safe union that can store one of several types, making it a versatile tool for returning either a result or an error type from a function. This is analogous to using tagged unions in C but with the added safety and flexibility offered by modern C++.Example for variant#include &lt;iostream&gt;#include &lt;variant&gt;#include &lt;string&gt;// Value Error Typestruct ValueError {      std::string message;  };    // Syntax Error Typestruct SyntaxError {      std::string message;  };  // Result type can be an integer, a value error, or a syntax errorusing Result = std::variant&lt;int, ValueError, SyntaxError&gt;;    Result riskyFunction(int value) {      // Return a ValueError if the input is negative    if (value &lt; 0)  return ValueError{\"Value cannot be negative\"};          // Return a SyntaxError if the input is zero    if (value == 0) return SyntaxError{\"Value cannot be zero\"};      // Return the value    return value * 2;  }    int main() {      auto result = riskyFunction(0);          // Check for a ValueError    if (std::holds_alternative&lt;ValueError&gt;(result)) {       std::cout &lt;&lt; \"Value error: \" &lt;&lt; std::get&lt;ValueError&gt;(result).message &lt;&lt; \"\\n\";         exit(0);    }        // Check for a SyntaxError    if (std::holds_alternative&lt;SyntaxError&gt;(result)) {       std::cout &lt;&lt; \"Syntax error: \" &lt;&lt; std::get&lt;SyntaxError&gt;(result).message &lt;&lt; \"\\n\";         exit(0);    }    // Otherwise, an integer result is assumed    std::cout &lt;&lt; \"Result: \" &lt;&lt; std::get&lt;int&gt;(result) &lt;&lt; \"\\n\";        return 0;  }In this instance, riskyFunction returns a std::variant&lt;int, ValueError, SyntaxError&gt;, allowing it to return either a valid result or detailed error information. This approach increases the granularity of error handling while avoiding the performance drawbacks associated with exceptions.Encapsulating Error Codes within ClassesAnother modern C++ approach involves encapsulating error codes within a class structure. This method enhances code readability and maintainability by associating specific error codes with meaningful class types, as opposed to relying on plain integers.We will first define a basic ErrorCode class to encapsulate error types and messages, then construct a Result class template that encapsulates either a value or an error. Finally, we will demonstrate how to utilize these classes in a function that performs a potentially risky operation and returns either a result or an error.Defining the ErrorCode ClassThe initial step in constructing our error-handling framework involves defining an ErrorCode class. This class will represent various types of errors that may occur and will provide a mechanism to retrieve an error message associated with each error type.Here is the basic structure of the ErrorCode class:// ErrorCode class to represent possible errorsclass ErrorCode { public:    // Enum to define different types of error codes    enum Code { None, ValueError, SyntaxError };    // Constructor takes an optional error code and an error message    explicit ErrorCode(Code code = None, std::string message = \"\")        : code_(code), message_(std::move(message)) {}    // Getter for the error message    std::string message() const { return message_; }    // Getter for the error code    Code code() const { return code_; } private:    Code code_;                ///&lt; error code / type    std::string message_;      ///&lt; error message};In this structure:  Enum Code: Enumerates different error types (None, ValueError, SyntaxError).  Constructor: Initializes the error code and its associated message.  Getters: Provide access to the error code and message.This class forms the foundation for representing errors within our application.Creating the Result Class TemplateNext, we need a way to return either a valid result or an error from a function. To achieve this, we create a Result class template that can hold either a value of any type T or an ErrorCode.The Result class is defined as a template, allowing it to accommodate any data type as the potential result of an operation. This flexibility is crucial for creating a general-purpose error-handling mechanism.template &lt;typename T&gt;class Result {    // Class members and methods will be defined within this template.};By templating the class, we enable Result to handle various types of results, making it adaptable to different contexts within an application.The Result class is designed to accommodate two primary scenarios:  The operation succeeds and returns a value, or  The operation fails and returns an error.To facilitate these scenarios, the class provides two constructors.public:    // Constructor for a successful result containing a value    explicit Result(T value) : result_(std::move(value)) {}    // Constructor for an error result containing an ErrorCode    Result(ErrorCode error) : result_(std::move(error)) {}      Success Constructor: This constructor initializes the Result object with a value of type T. The use of std::move ensures efficient handling of the value, particularly when dealing with large or complex objects.        Error Constructor: This constructor initializes the Result object with an ErrorCode, signifying that the operation encountered an issue.  These constructors are fundamental to ensuring that the Result object can accurately represent either a successful outcome or an error, providing a clear and structured approach to error handling.To enable the Result object to hold either a value or an error, the class employs std::variant. This C++ standard library feature ensures that the object can store one of these types at a time, but not both simultaneously.private:    std::variant&lt;T, ErrorCode&gt; result_; ///&lt; Holds either a value of type T or an ErrorCodeThe std::variant type is integral to the design of the Result class. It enforces type safety by ensuring that the object contains only a value or an error at any given moment, thus preventing ambiguous states.A common requirement when dealing with the outcome of an operation is the ability to easily determine whether it succeeded or failed. The Result class provides an overloaded bool operator to facilitate this check.public:    // Overloaded bool operator to check if the result contains a value (indicating success)    explicit operator bool() const {        return std::holds_alternative&lt;T&gt;(result_);    }  Boolean Operator: This operator checks whether the Result contains a value of type T. If it does, the operator returns true, indicating success; otherwise, it returns false.This feature enhances the usability of the Result class by allowing developers to intuitively and efficiently check the success of an operation.To access the value or error contained within the Result object, the class provides two methods: value() and error(). These methods return std::optional types, which offer a safe way to handle cases where the requested data might not be present.public:    // Retrieve the value if no error occurred, returning std::optional to handle the absence of a value    std::optional&lt;T&gt; value() const {        if (std::holds_alternative&lt;T&gt;(result_)) {            return std::get&lt;T&gt;(result_);        }        return std::nullopt;    }    // Retrieve the error if one occurred, returning std::optional to handle the absence of an error    std::optional&lt;ErrorCode&gt; error() const {        if (std::holds_alternative&lt;ErrorCode&gt;(result_)) {            return std::get&lt;ErrorCode&gt;(result_);        }        return std::nullopt;    }      value() Method: This method attempts to retrieve the stored value. If the Result contains a value, it is returned; if the Result contains an error, the method returns std::nullopt, indicating the absence of a value.        error() Method: Similarly, this method retrieves the stored error if one is present. If the Result contains a value instead, it returns std::nullopt, signifying the absence of an error.  These methods provide a clear and safe mechanism for extracting the contents of the Result object, ensuring that error handling is both explicit and reliable.The Result class template offers a comprehensive and type-safe mechanism for managing the outcomes of operations that may either succeed or fail. By encapsulating both the value and the error within a single object, it presents a clean and efficient alternative to traditional error-handling strategies, making it particularly suitable for environments where reliability and performance are critical.Implementing the Result Class in a FunctionWith the ErrorCode and Result classes defined, we can now use them in a function that performs a potentially risky operation. The function will return a Result&lt;int&gt; to indicate either a successful operation (yielding a result) or an error.Here’s an example of such a function:Result&lt;int&gt; riskyFunction(int value) {    // If the input value is negative, return a ValueError    if (value &lt; 0) {        return ErrorCode(ErrorCode::ValueError, \"Value cannot be negative\");    }    // If the input value is zero, return a SyntaxError    if (value == 0) {        return ErrorCode(ErrorCode::SyntaxError, \"Value cannot be zero\");    }    // Input is correct    return Result&lt;int&gt;(value * 2); // Return the result on success}where  Negative Value: Returns an ErrorCode for a ValueError.  Zero Value: Returns an ErrorCode for a SyntaxError.  Valid Value: Returns the computed result (value * 2).This function demonstrates how to use the Result and ErrorCode classes to handle errors in a structured manner.Managing the Result in the Main FunctionFinally, we can handle the result of riskyFunction in the main function:int main() {    // Call riskyFunction with an input value of 5    auto result = riskyFunction(5);    // Check if the result contains an error    if (!result) {        // Retrieve the error from the result        auto error = result.error();        // Check if the error is a ValueError and print the error message        if (error &amp;&amp; error-&gt;code() == ErrorCode::ValueError) {            std::cout &lt;&lt; \"Value Error: \" &lt;&lt; error-&gt;message() &lt;&lt; \"\\n\";            exit(0); // or return        }        // Check if the error is a SyntaxError and print the error message        if (error &amp;&amp; error-&gt;code() == ErrorCode::SyntaxError) {            std::cout &lt;&lt; \"Syntax Error: \" &lt;&lt; error-&gt;message() &lt;&lt; \"\\n\";            exit(0); // or return        }    }     // print the successful result value    std::cout &lt;&lt; \"Result: \" &lt;&lt; *result.value() &lt;&lt; \"\\n\";    return 0;}where  Check for Error: The if (!result) block checks if an error occurred.  Handle ValueError: If the error is a ValueError, print the message and exit.  Handle SyntaxError: If the error is a SyntaxError, print the message and exit.  Print Result: If no error occurred, print the result.This approach is particularly advantageous in environments where exceptions are disabled or in performance-critical applications where the overhead of exceptions is undesirable. The combination of std::variant, std::optional, and custom error codes provides a robust alternative that enhances both code readability and maintainability.ConclusionIn the highly specialized field of embedded systems development, where resources are tightly constrained, the use of traditional C++ exceptions is often impractical. By adopting alternative techniques such as low-level goto and function pointers, or more sophisticated methods like setjmp and longjmp, developers can implement effective error-handling mechanisms with minimal overhead. Each approach has its advantages and trade-offs, which must be carefully evaluated based on the specific constraints and requirements of the application at hand.For a quick recap, here is a comparison between discussed methods:            Method      Advantages      Disadvantages                  goto and Function Pointers      - Extremely low overhead, close to the hardware level  - Simple to implement in small, constrained environments      - Prone to errors and difficult to maintain  - Lacks flexibility and scalability  - No automatic cleanup              setjmp and longjmp      - Provides a mechanism for non-local jumps and structured error handling without exceptions  - Suitable for more complex control flows      - Requires manual resource management (no stack unwinding)  - Can be complex to implement correctly              Typed Exceptions with longjmp      - Allows handling different types of errors distinctly  - Offers more granularity in error management      - Complexity in implementation  - Manual resource management required              Exception Cascades with longjmp      - Enables complex control flow and exception propagation  - Flexible error-handling strategy      - Even higher complexity  - Difficult to debug and maintain  - Requires thorough testing and validation              Custom Exception Handler      - Mimics higher-level try/catch behavior in embedded C/C++ without runtime overhead- More structured and organized error handling      - Increased complexity  - Requires manual resource registration and cleanup  - Potential for missed cleanup              goto for Cleanup      - Simple and straightforward for resource cleanup  - Simplifies resource cleanup operations in basic scenarios      - Lacks abstraction and safety  - Can lead to spaghetti code and is unsuitable for complex error handling              Raw std::optional and std::variant      - Modern C++ features with low overhead, compatible with resource-constrained environments  - Type-safe and integrates well with existing codebases      - Limited expressiveness compared to full exception handling  - Still requires manual checks and error handling              Result Class Template      - Encapsulates error handling in a type-safe manner  - Provides clear and maintainable code structure  - Avoids the runtime overhead of exceptions      - Increased code complexity  - May be over-engineered for simple error-handling cases      In conclusion, there is no one-size-fits-all solution for error handling in embedded systems. The best approach often involves a careful balance between simplicity, efficiency, and flexibility, tailored to the unique challenges of the target environment. By leveraging the techniques discussed in this article, developers can ensure that their embedded systems remain resilient, even in the face of unexpected errors."
  },
  
  {
    "title": "CMake - Publish Your Own Library",
    "url": "/posts/CMake-Production/",
    "categories": "Software-Development, Cmake",
    "tags": "Software, Cmake, Windows, C++, Library, Cross-Platform, Build-Systems, Dependency-Management, Continuous-Integration, CI, CD/CI",
    "date": "2023-11-18 13:00:00 +0100",
    





    
    "snippet": "Introduction to Publishing CMake ProjectsWhen developing a C++ library, especially one meant to be reused across multiple projects or distributed to others, it’s crucial to structure your project e...",
    "content": "Introduction to Publishing CMake ProjectsWhen developing a C++ library, especially one meant to be reused across multiple projects or distributed to others, it’s crucial to structure your project effectively and use a build system that facilitates this process. CMake is a powerful and widely-used build system that helps manage the build process in a platform-independent manner. This tutorial will guide you through the process of structuring and publishing your own CMake project, ensuring that your library is not only well-organized but also easy to build, test, and distribute.CMake projects are organized to streamline the development process, allowing for easy integration of dependencies, consistent build processes across different platforms, and a clear separation between the public API, private code, and other components like tests. By following a well-defined structure, you make your project more maintainable and accessible to other developers, who can easily understand and contribute to your code.ObjectivesThe primary objective of this article is to provide a comprehensive guide on setting up a CMake-based C++ project for public release. We will cover essential topics such as project structure, CMake configuration, handling platform-specific dependencies, and defining installation rules. By the end of this guide, you will be equipped to publish a well-organized, portable, and easily integrable library.However, this guide will focus on the CMake configuration and project structuring aspects, rather than delving deeply into the testing or the internal implementation of the library itself. Testing will be mentioned briefly, but the core emphasis will be on preparing your library for public consumption through CMake.Project Structure OverviewThe structure of a CMake project plays a significant role in how easily it can be built, tested, and integrated into other projects. A well-organized project directory helps in separating different concerns such as public headers, source files, dependencies, and configuration files. Below is a typical structure for a CMake-based C++ project, which we will dissect:my_library_project/                # Project Folder│├── CMakeLists.txt                 # Root CMake configuration file├── cmake/│   └── my_libraryConfig.cmake.in  # CMake config template for installation│├── dependencies/                  # External dependencies for different platforms│   ├── win_x86_64/                # Dependencies for Windows x64│   └── linux_x86_64/              # Dependencies for Linux x64│├── include/                       # Public header files exposed to users│   └── my_library/                # Library-specific headers│       ├── my_library.h           # Main public API header│       └── my_project_export.h    # Export macros for DLLs/shared libraries│├── my_library/                    # Source code for the library│   ├── CMakeLists.txt             # Module-specific CMake configuration│   ││   ├── internal/                  # Internal headers (not exposed to users)│   │   └── internal_helpers.h     # Helpers and private interfaces│   ││   └── source/                    # Implementation files│       ├── my_library.cpp         # Implementation of the public API│       └── internal_helpers.cpp   # Implementation of internal functionality│    │└── tests/                         # Test code for the library    ├── CMakeLists.txt             # CMake Configuration for tests    └── test_my_library.cpp        # Unit or integration testsBreakdown of the Project Structure      CMakeLists.txt (Root Level):    This file serves as the entry point for CMake, defining the project’s configuration and build settings. It sets the required CMake version, specifies the C++ standard, configures platform-specific dependencies, and adjusts compiler flags based on the build type. The file also defines output directories and includes subdirectories for building the main library and associated tests. Additionally, it manages required packages and ensures compatibility across different platforms. (jump to this section)        cmake/ Directory:    Contains custom CMake modules and configuration templates, such as my_libraryConfig.cmake.in, which is used for packaging and installing your library. This template allows users to find and link against your library using find_package. (jump to this section)        dependencies/ Directory:    This is where you would store any external dependencies your project relies on, especially if they are platform-specific. Subdirectories can be organized by platform, such as win_x86_64 for Windows and linux_x86_64 for Linux. Including dependencies here makes it easier to manage third-party libraries that are not readily available through package managers. Once your library is exported, you can re-utilize your library in another project, by putting it here.        include/ Directory:    This folder contains the public API headers. These are the files that other projects will include when they use your library. The headers are usually organized in a subdirectory named after your library (e.g., my_library/).  The main API header (my_library.h) should include the core functions and classes, while the my_project_export.h file handles macro definitions that control symbol visibility, which is crucial when building shared libraries.        my_library/ Directory:    This is the main codebase of your library. It typically contains a CMakeLists.txt file if the module needs its own build rules, an internal/ directory for private headers not exposed to users, and a source/ directory for the implementation files (.cpp). This separation between internal and public components helps in encapsulating the internal details of your library.        tests/ Directory:    Contains unit or integration tests that validate your library’s functionality. These tests are usually written using a testing framework (like Google Test, Catch2, or Boost.Test) and should cover both the public API and critical internal components. The test_my_library.cpp file is an example test that might include various test cases to ensure your library works as expected. Here we will, however, focus on the project structure rather than on testing.  Export OverviewOnce you install your library, the installation/ directory will contain everything required for others to use and integrate your library into their own projects. Let’s break down each component within this directory:installation/                                  # Project installation root directory│├── bin/                                       # Contains runtime binaries (e.g., DLLs) if provided│   └── libmy_library.dll                      # Compiled dynamic library (Windows)|├── include/                                   # Public header files that exposed to users│   └── my_library/                            # Namespace for your library headers│       ├── my_library.h                       # Primary public API header│       ├── ...                                # Your public API headers│       └── my_project_export.h                # Export macros for cross-platform compatibility│└── lib/                                       # Library and CMake configuration files    ├── cmake/                                 # CMake package configuration directory    |   └── my_library/                        # CMake files for library integration    |       └── my_libraryConfig.cmake         # Configuration file for `find_package`    |       └── my_libraryConfigVersion.cmake  # Version-specific config for compatibility checks    |       └── my_libraryTargets.cmake        # Target definitions for linking the library    └── libmy_library.dll.a                    # Import library for GCC/MinGW (or .lib for MSVC)Breakdown of the Installation Structure      bin/ Directory:    The bin/ directory holds the runtime binaries of the library.  It contains the dynamically linked libraries (DLLs) for Windows, which are necessary at runtime when your library is used by external applications.  These binaries are dynamically loaded during program execution and contain the compiled functionality of the library.    libmy_library.dll: This is the main dynamic library file for Windows, containing the compiled code that is loaded at runtime. It provides the core functionality of your library to the consumers.        include/ Directory:    This directory contains all the public API headers that your users will include in their projects to interface with your library.  These headers define the classes, functions, and macros that are exposed to external projects.  Organizing them in a subdirectory named after the library ensures clear separation and namespace management.    my_library.h: The main public header file, this aggregates all the core functions and classes available in your library. It serves as the primary interface for users to access your library’s functionality.    my_project_export.h: This header defines export macros used for symbol visibility across platforms.        lib/ Directory:    The lib/ directory contains the static or import libraries and the CMake configuration files necessary for integrating your library with other projects. This directory allows your library to be discovered and linked using CMake’s find_package command.                  cmake/ Directory:    This subdirectory contains the CMake configuration files needed to allow other projects to find and link to your library. The files ensure that CMake knows how to configure, locate, and use your library’s targets.                    my_libraryConfig.cmake:    This is the main CMake configuration file used by find_package. It provides instructions on how to locate the library, including setting the paths for the library binaries and headers, and ensuring that the library is correctly linked.        You define this file by using a template in the cmake folder in your project.  (jump to this section)                    my_libraryConfigVersion.cmake:    This file ensures version compatibility between the library and the consuming project. It allows CMake to check whether the version of the library being used meets the version constraints specified in the consuming project.                    my_libraryTargets.cmake:    This file defines the targets associated with your library. It provides CMake with the necessary details for linking the library, including any dependencies or settings required by the consumer project.                    libmy_library.dll.a:    This is the import library for GCC/MinGW, which allows projects to link against the .dll file. For MSVC, this would be a .lib file. It plays a critical role in the linking phase of the build process, providing the required interface to the shared library.            Root CMakeLists.txtThe root CMakeLists.txt file is the cornerstone of your project’s build configuration. It defines the essential settings and directives that guide CMake in compiling, linking, and packaging your project. Writing a well-structured CMakeLists.txt ensures that your project is not only maintainable but also portable across different environments and platforms. Below is a detailed explanation of the key components of this file.Minimum CMake Version and Project DefinitionTo start, you must define the minimum version of CMake that is required to build your project, as well as the project name and version. This is not only a formality but also a fundamental part of your project’s identity.cmake_minimum_required(VERSION 3.20)project(my_library_project VERSION 0.1.0)The cmake_minimum_required command specifies the minimum version of CMake that is required to build your project. This ensures that all developers and continuous integration systems use a compatible version of CMake, avoiding potential issues caused by deprecated or unavailable features in older versions. Here, version 3.20 is chosen to leverage modern CMake capabilities.The project command defines the name of the project and its version. This is critical as it not only names your project but also associates a version number with it, which can be useful for packaging and version control purposes.C++ Standard ConfigurationIn a C++ project, it’s critical to enforce a specific C++ standard across all compiled files to ensure consistency and avoid compatibility issues between different compilers or environments.# This specifies that the C++20 standard should be enforced for all targets.set(CMAKE_CXX_STANDARD 20)set(CMAKE_CXX_STANDARD_REQUIRED ON)set(CMAKE_CXX_EXTENSIONS OFF)      CMAKE_CXX_STANDARD is set to 20, which enforces the C++20 standard.        The CMAKE_CXX_STANDARD_REQUIRED directive ensures that the build process will halt if the compiler does not support C++20, preventing potential issues later.        Disabling CMAKE_CXX_EXTENSIONS avoids using compiler-specific language extensions, which enhances the portability of your code across different compilers.  Compiler Flags Based on Build TypeCompiler flags are instrumental in controlling the behavior of the compiler, particularly when distinguishing between Debug and Release builds. This section configures these flags to optimize for either debugging or performance, depending on the build type.if(CMAKE_BUILD_TYPE STREQUAL Debug)    message(STATUS \"Configuring for a Debug build\")    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -Wall -g3 -Og\")    add_definitions(-DDEBUG_MODE)else()    message(STATUS \"Configuring for a Release build\")    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -Wall -g0 -O3\")endif()In Debug mode, the flags enable detailed debugging information (-g3) and turn off aggressive optimizations (-Og) to make the debugging process more straightforward.Additionally, a DEBUG_MODE macro is defined, which can be used within your code to conditionally include debug-specific logic.In Release mode, the configuration focuses on optimization (-O3) and minimal debug information (-g0) to ensure maximum performance.Platform-Specific Dependency ConfigurationHandling dependencies can be complex, especially when targeting multiple platforms. This section of the CMakeLists.txt is designed to manage platform-specific dependencies and packaging configurations.# Define the platform-specific paths and packaging configurations.# This ensures that the correct dependencies are used depending on the platform.if(WIN32)    # Set the dependency folder for Windows x64.    set(DEPENDENCY_FOLDER \"${CMAKE_SOURCE_DIR}/dependencies/win_x86_64/\")    # Use ZIP as the packaging format for Windows.    set(CPACK_GENERATOR \"ZIP\")elseif (UNIX AND NOT APPLE)    # Set the dependency folder for Linux x64.    set(DEPENDENCY_FOLDER \"${CMAKE_SOURCE_DIR}/dependencies/linux_x86_64/\")        # Use TGZ (tarball gzip) as the packaging format for Linux.    set(CPACK_GENERATOR \"TGZ\")else()    # Fatal error if the platform is unsupported.    message(FATAL_ERROR \"Unsupported Platform: ${CMAKE_SYSTEM_NAME}\")endif()This code block first checks the platform being used (WIN32 for Windows or UNIX for Linux) and then sets the appropriate directory for dependencies and the correct packaging format (ZIP for Windows and TGZ for Linux). If the platform is not supported, CMake will throw a fatal error, stopping the build process.CMake Prefix PathThe CMAKE_PREFIX_PATH variable is used to specify additional directories where CMake should look for packages, particularly when they are not located in standard system paths. This is especially useful when working with third-party libraries that are bundled with your project.# Set the CMake prefix path to include platform-specific dependency directories.# This helps CMake locate the required libraries and packages.set(CMAKE_PREFIX_PATH        \"${DEPENDENCY_FOLDER}/pkgconfig/\"        \"${DEPENDENCY_FOLDER}/some_library/\")By setting the CMAKE_PREFIX_PATH, you direct CMake to search in the specified directories for the necessary libraries and packages, ensuring that the build process can locate and link all required dependencies.Of course this assumes the dependencies are set for all platforms.my_library_project/               └── dependencies/       ├── win_x86_64/         |   ├── pkgconfig/               |   └── some_library/       └── linux_x86_64/          ├── pkgconfig/                   └── some_library/   Finding and Configuring PackagesFinding and linking external libraries is a common requirement in C++ projects. The find_package command helps automate this process by locating the necessary libraries and integrating them into your project.find_package(PkgConfig REQUIRED)Here, we use find_package to locate the PkgConfig tool, which is required to manage the inclusion of external libraries. By marking it as REQUIRED, we ensure that the build process will stop with an error if PkgConfig is not found, preventing any further issues.Output Directory ConfigurationTo keep the build process organized, it’s important to specify where the compiled binaries and libraries should be output. This not only makes it easier to locate the build artifacts but also keeps your project directory clean.# Set the output directories for the project.# These settings ensure that all binaries, libraries, and archives are organized in one place.set(CMAKE_RUNTIME_OUTPUT_DIRECTORY \"${CMAKE_SOURCE_DIR}/output\")set(CMAKE_LIBRARY_OUTPUT_DIRECTORY \"${CMAKE_SOURCE_DIR}/output\")set(CMAKE_ARCHIVE_OUTPUT_DIRECTORY \"${CMAKE_SOURCE_DIR}/output/lib\")This configuration sets all the runtime executables, shared libraries, and static libraries to be placed in a central output directory. The distinction between runtime, library, and archive outputs ensures that the files are well-organized.Adding SubdirectoriesIn complex projects, organizing your code into subdirectories makes it easier to manage and maintain. The add_subdirectory command allows you to include additional CMake configurations from different parts of your project.# Add subdirectories for the library and tests. # This modular approach keeps the project organized and easy to manage.add_subdirectory(my_library)add_subdirectory(tests)By adding subdirectories, you modularize your project, allowing each component, such as the core library and its tests, to have its own CMakeLists.txt file. This makes the overall project more maintainable and scalable.Library CMakeLists.txtNow we will look at each section of the my_library/CMakeLists.txt file, explaining the purpose and nuances of each part.Defining the Library TargetIn modern CMake, source files for a library are explicitly listed and associated with the target. This approach makes the build process clear and maintainable.# Define the my_library library targetadd_library(my_library SHARED)# Add sources to the my_library library targettarget_sources(my_library PRIVATE        source/my_library.cpp        source/internal_helpers.cpp        # Add more files as needed)      add_library(my_library SHARED): This command defines a new library target named my_library and specifies that it should be built as a shared library (SHARED).        target_sources(my_library PRIVATE ...): This command explicitly adds the specified source file (my_library.cpp) to the my_library library target. The PRIVATE keyword indicates that the source file is only relevant to this specific target and will not be exposed to other targets.  Passing Version Information to the Source CodePassing the version number to the source code can be useful for embedding version information into the compiled library, which can be accessed at runtime.target_compile_definitions(my_library PRIVATE MY_LIBRARY_VERSION=\"${PROJECT_VERSION}\")target_compile_definitions(my_library PRIVATE MY_LIBRARY_VERSION=\"${PROJECT_VERSION}\"): This command defines a preprocessor macro (MY_LIBRARY_VERSION) with the value of the project’s version (${PROJECT_VERSION}), making this version accessible in the source code. The PRIVATE keyword indicates that this definition is only available within the my_library target and not propagated to targets that link against this library.Setting Build Flags for the LibraryDefining specific macros during the build process is essential for controlling how the library is compiled and differentiating between internal and external usage of the library. (see the section about declaring visiblity)target_compile_definitions(my_library PRIVATE BUILDING_MY_LIBRARY=\"1\")target_compile_definitions(my_library PRIVATE BUILDING_MY_LIBRARY=\"1\"): This command establishes the BUILDING_MY_LIBRARY macro with a value of “1”, signaling that the current build is for the library itself. This distinction is crucial for correctly applying the visibility attributes defined earlier, ensuring that internal components are exported properly while maintaining clean separation from the end-user’s environment.Specifying Include DirectoriesInclude directories are necessary for resolving header files during compilation. It’s important to specify both build-time and install-time include directories.# Specify the include directories for the targettarget_include_directories(my_library    PUBLIC        # Use absolute path for building        $&lt;BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/../include&gt;        # Use relative path for installation        $&lt;INSTALL_INTERFACE:include&gt;    PRIVATE        ${CMAKE_CURRENT_SOURCE_DIR}/internal)  target_include_directories(my_library PUBLIC ...): This command sets up include directories for the my_library target. The PUBLIC keyword indicates that these directories should be used both when building the library and when other targets include this library.  $&lt;BUILD_INTERFACE:...&gt; and $&lt;INSTALL_INTERFACE:...&gt;: These generator expressions ensure that different paths are used depending on whether the library is being built (BUILD_INTERFACE) or installed (INSTALL_INTERFACE). This separation ensures that the correct paths are used in each context, enhancing portability.  PRIVATE ${CMAKE_CURRENT_SOURCE_DIR}/internal: This directory is used for internal headers that should not be exposed to users of the library. The PRIVATE keyword indicates that these include directories are only used when compiling this target.Linking External LibrariesTo use external libraries like libmicrohttpd, you need to find and link them to your project. CMake offers several ways to find libraries, including find_library.# Find and link the required libmicrohttpd library using pkg-configfind_library(MICROHTTPD_LIB NAMES microhttpd libmicrohttpd)# Link the static microhttpd librarytarget_link_libraries(my_library PRIVATE ${MICROHTTPD_LIB})  find_library(MICROHTTPD_LIB NAMES microhttpd libmicrohttpd): This command searches for the libmicrohttpd library, storing the path in the MICROHTTPD_LIB variable. The NAMES option specifies possible names for the library, accommodating different naming conventions on various systems.  target_link_libraries(my_library PRIVATE ${MICROHTTPD_LIB}): This command links the libmicrohttpd library to the my_library target. The PRIVATE keyword ensures that this linkage is only relevant for the my_library target and is not inherited by other targets that depend on it.Configuring Visibility for Internal FunctionsTo reduce the binary size and improve load times, it’s important to hide internal symbols that do not need to be exposed outside the library.target_compile_options(my_library PRIVATE -fvisibility=hidden)set_target_properties(my_library PROPERTIES CXX_VISIBILITY_PRESET hidden)set_target_properties(my_library PROPERTIES VISIBILITY_INLINES_HIDDEN YES)  target_compile_options(my_library PRIVATE -fvisibility=hidden): This option hides symbols by default, making only explicitly marked symbols (using __attribute__((visibility(\"default\")))) visible outside the library.  set_target_properties(... PROPERTIES CXX_VISIBILITY_PRESET hidden): This sets the default visibility of C++ symbols to hidden.  set_target_properties(... PROPERTIES VISIBILITY_INLINES_HIDDEN YES): This command hides inline function symbols, further reducing the number of exported symbols and improving binary efficiency.Defining Installation Rules for the LibraryInstalling your library correctly ensures that it can be easily found and used by other projects. The installation rules specify where the library files will be placed on the target system.# Installation Rules# Define the installation directoriesinstall(TARGETS my_library        EXPORT my_libraryTargets        ARCHIVE DESTINATION lib        LIBRARY DESTINATION lib        RUNTIME DESTINATION bin        INCLUDES DESTINATION include)  install(TARGETS my_library ...): This command defines how the my_library library should be installed. The ARCHIVE, LIBRARY, and RUNTIME options specify the directories for different types of build outputs (static libraries, shared libraries, and executables, respectively). The INCLUDES DESTINATION specifies where the public headers will be installed.  EXPORT my_libraryTargets: This option exports the target, which allows it to be included in the package configuration files, making the library discoverable by other projects using find_package.Installing Public Headersinstall(DIRECTORY ../include/ DESTINATION include)Alongside the compiled library, you must install the public headers so that they can be included by other projects.  install(DIRECTORY ../include/ DESTINATION include): This command installs the contents of the public include/ directory to the include directory on the target system. This is essential for making the public API available to other projects that depend on your library.Installing Package Configuration Files# Install the package configuration filesinstall(EXPORT my_libraryTargets        FILE my_libraryTargets.cmake        NAMESPACE my_library::        DESTINATION lib/cmake/my_library)# Create and install the package configuration filesinclude(CMakePackageConfigHelpers)write_basic_package_version_file(        \"${CMAKE_CURRENT_BINARY_DIR}/my_libraryConfigVersion.cmake\"        VERSION ${PROJECT_VERSION}        COMPATIBILITY AnyNewerVersion)configure_package_config_file(        \"../cmake/my_libraryConfig.cmake.in\"        \"${CMAKE_CURRENT_BINARY_DIR}/my_libraryConfig.cmake\"        INSTALL_DESTINATION lib/cmake/my_library)install(FILES        \"${CMAKE_CURRENT_BINARY_DIR}/my_libraryConfig.cmake\"        \"${CMAKE_CURRENT_BINARY_DIR}/my_libraryConfigVersion.cmake\"        DESTINATION lib/cmake/my_library)To make your library discoverable by CMake’s find_package, you need to generate and install package configuration files.  install(EXPORT my_libraryTargets ...): This command exports the target configuration, allowing it to be used by find_package when other projects search for my_library.  include(CMakePackageConfigHelpers): This includes helpers for generating package configuration files.  write_basic_package_version_file(...): Generates a version file that defines the compatibility of the library with different versions.  configure_package_config_file(...): Configures the main package configuration file, which helps other projects find and link against your library.  install(FILES ...): Installs the generated configuration files to the appropriate directory.Configuring Package Information for DistributionFinally, to make the library distributable, package information such as the package name, version, and contact details is configured using CPack.# Set the package name and versionset(CPACK_PACKAGE_NAME \"my_library\")set(CPACK_PACKAGE_VERSION ${PROJECT_VERSION})set(CPACK_PACKAGE_CONTACT \"Mustafa Alotbah &lt;mustafa.alotbah@gmail.com&gt;\")# CPACK_GENERATOR set by root CMakeLists.txtinclude(CPack)  set(CPACK_PACKAGE_NAME \"my_library\"): Sets the name of the package for distribution.  set(CPACK_PACKAGE_VERSION ${PROJECT_VERSION}): Sets the package version, aligning it with the project version.  set(CPACK_PACKAGE_CONTACT \"Mustafa Alotbah &lt;mustafa.alotbah@gmail.com&gt;\"): Provides contact information for the package, useful for users or maintainers.  include(CPack): Includes CPack, which handles the creation of distribution packages based on the specified configuration.CMake Template FileThe my_libraryConfig.cmake.in file is a template used by CMake to generate a my_libraryConfig.cmake file during the installation process. This configuration file plays a crucial role in making your library discoverable and easily integrable into other projects through CMake’s find_package command.@PACKAGE_INIT@include(\"${CMAKE_CURRENT_LIST_DIR}/my_libraryTargets.cmake\")The my_libraryConfig.cmake.in file typically contains initialization code and references to other generated files, such as the my_libraryTargets.cmake:      @PACKAGE_INIT@ Macro is a placeholder that is replaced by CMake with the necessary initialization code when the file is processed. The @PACKAGE_INIT@ macro is essential as it sets up the environment for the package configuration. It ensures that any necessary CMake variables are initialized and that the package configuration is compatible with the CMake version used by the consuming project.        Including the my_libraryTargets.cmake File: This line includes the my_libraryTargets.cmake file, which contains the actual definitions of the targets (such as the my_library library) that will be exported during the installation process.This inclusion is critical for making the targets available to projects that use find_package to locate your library.          Including the my_libraryTargets.cmake file is what allows other projects to link against your library. It ensures that all necessary targets, build settings, and dependencies are correctly set up in the consuming project. Without this inclusion, the library would not be properly registered with CMake, making it unavailable for use.      Defining IMPORTED_IMPLIB for Windows PlatformsWhen distributing libraries on Windows, there are often differences in how dynamic libraries (.dll) are linked, depending on the compiler. For this, we use the IMPORTED_IMPLIB property in CMake to define the appropriate import library (.lib or .dll.a) for Windows toolchains.We can check if we are on Windows platform if (WIN32) and in this case we should distinguish between MinGW/GCC where .dll.a is used, whereas .lib is used by MSVC compilers.if (WIN32)    # Check for GNU / Mingw Compilers    if (CMAKE_CXX_COMPILER_ID MATCHES \"GNU|MinGW\")        # Configure `IMPORTED_IMPLIB` to point to the .dll.a library that will be created        set_target_properties(Logify::Logify PROPERTIES            IMPORTED_IMPLIB \"${CMAKE_CURRENT_LIST_DIR}/../../libmy_library.dll.a\")    # Otherwise assume it is MSVC    else()        # Configure `IMPORTED_IMPLIB` to point to the .lib library that will be created        set_target_properties(Logify::Logify PROPERTIES            IMPORTED_IMPLIB \"${CMAKE_CURRENT_LIST_DIR}/../../libmy_library.lib\")    endif()endif()Source CodeWhen designing a C++ library that will be used by other projects, it is crucial to manage the visibility of functions and symbols properly. This is particularly important when creating shared libraries, where you want to expose only the necessary API functions while keeping internal details hidden.Source Code StructureFor demonstration purposes, we will implement a simple API function, std::string getVersion(), which returns the version of the library. This API function will internally rely on another function, std::string internalGetVersion(), which should remain hidden from the library users. The internal function will only be accessible within the library’s codebase.Given that we have configured the default visibility of all symbols to be hidden (as detailed in the section on configuring visibility for internal functions), we must explicitly declare which symbols should be visible to the outside world. This is achieved using visibility attributes that are platform-specific.Declaring Visibility in Header FilesTo control the visibility of our API and internal functions, we use different attributes depending on the platform.For GCC and MSVC on WindowsWhen compiling a shared library on Windows, the __declspec(dllexport) attribute is used to export functions from a DLL, making them available to other projects that link against the DLL. Conversely, __declspec(dllimport) is used in the client code to import these functions. We encapsulate this logic in a macro MY_LIBRARY_API:#ifdef BUILDING_MY_LIBRARY#define MY_LIBRARY_API __declspec(dllexport)#else#define MY_LIBRARY_API __declspec(dllimport)#endifFor GCC on LinuxOn Linux, GCC provides a visibility attribute, __attribute__((visibility(\"default\"))), which is used to mark symbols that should be visible outside the library. We also define an internal visibility attribute to explicitly hide symbols:#if defined(__GNUC__) &amp;&amp; __GNUC__ &gt;= 4#define MY_LIBRARY_API __attribute__((visibility(\"default\")))#else#define MY_LIBRARY_API#endifCombined Platform-Independent DefinitionTo maintain cross-platform compatibility, we combine these definitions into a single header file, my_project_export.h. This header ensures that the correct visibility attributes are applied based on the target platform:#pragma once#ifdef _WIN32#ifdef BUILDING_MY_LIBRARY#define MY_LIBRARY_API __declspec(dllexport)#else#define MY_LIBRARY_API __declspec(dllimport)#endif#else#if defined(__GNUC__) &amp;&amp; __GNUC__ &gt;= 4#define MY_LIBRARY_API __attribute__((visibility(\"default\")))#else#define MY_LIBRARY_API#endif#endif  The flag BUILDING_MY_LIBRARY is defined in the building process in the CMakeLists.txt of the library, see here. It is only defined in the build process of the library but must not be defined in the build process of the user.Public API DeclarationIn the public API header, my_library.h, we use the MY_LIBRARY_API macro to declare the visibility of the getVersion() function:#pragma once#include \"my_project_export.h\"#include &lt;string&gt;MY_LIBRARY_API std::string getVersion();This ensures that getVersion() is visible to any project that links against the library, while other internal functions remain hidden.Internal Function DeclarationIn contrast, the internal function internalGetVersion() is declared in an internal header, internal_helpers.h, without any visibility attributes, meaning it will remain hidden:#pragma once#include &lt;string&gt;std::string internalGetVersion();Since this header is marked as PRIVATE in the CMake configuration (as discussed in the section on specifying include directories), it is not exposed to the users of the library when the library is installed.Implementing the FunctionsThe internal function internalGetVersion() is implemented in the source/internal_helpers.cpp file. This function retrieves the version information, which we previously passed to the source code using a preprocessor definition in our CMake configuration:#include \"internal_server.h\"std::string internalGetVersion() {    return MY_LIBRARY_VERSION;}The MY_LIBRARY_VERSION macro was defined earlier in the CMake configuration (as detailed in the section on passing version information to the source code).The getVersion() API function, which calls the internal function, is implemented in source/my_library.cpp:#include \"my_library/my_library.h\"#include \"my_library_internal.h\"std::string getVersion() {    return internalGetVersion();}This structure ensures that while getVersion() is accessible to external projects, internalGetVersion() remains encapsulated within the library, hidden from external access.Verifying Visibility and Symbol ExportTo verify that only the intended symbols are exposed, you can inspect the exported symbols of the compiled shared library. On Linux, this can be done using the nm command:nm -C -D lib/libmy_library.so | grep \" T \"&gt;&gt;&gt; 0000000000001120 T getVersion[abi:cxx11]()This command lists all symbols marked as globally visible (T). As expected, only getVersion() is exposed.On Windows, you can use the dumpbin tool to inspect the DLL exports:dumpbin /EXPORTS libmy_library.dll&gt;&gt;&gt; ...    ordinal hint RVA      name          1    0 00001370 _Z10getVersionB5cxx11v  Summary...Again, only the getVersion() function is visible, confirming that the internal details of the library remain hidden as intended.Installing the ProjectAfter configuring and building the library, it is crucial to install it correctly. This ensures that all necessary files—binaries, headers, and configuration files—are placed in the appropriate directories, ready for use by other projects.mkdir build cd buildcmake .. -G \"MinGW Makefiles\" -DCMAKE_BUILD_TYPE=Releasecmake --build . --config Releasecmake --install . --prefix .These commands create a build directory, configure the project for a release build, and then install the library. The installation process places the compiled binaries, headers, and CMake configuration files in the specified prefix directory.To package the project for distribution, you can use CPack:cpackCPack generates a package (e.g., a ZIP or TGZ file) containing the installed files, making it easy to distribute the library."
  },
  
  {
    "title": "CMake - Integrating C++ Libraries",
    "url": "/posts/CMake-Integrating-C++-Libraries/",
    "categories": "Software-Development, Cmake",
    "tags": "Software, C++, Cmake, Windows",
    "date": "2023-11-15 17:08:00 +0100",
    





    
    "snippet": "In modern C++ development, CMake is an indispensable tool for managing project dependencies.This comprehensive guide empowers you to effortlessly integrate widely used C++ libraries into your proje...",
    "content": "In modern C++ development, CMake is an indispensable tool for managing project dependencies.This comprehensive guide empowers you to effortlessly integrate widely used C++ libraries into your projects using the versatile CMake build system.We’ll delve into strategies for incorporating Google Test, Google Benchmark, OpenCV, PkgFinder, GStreamer, Catch2, and Qt, providing clear instructions and code examples tailored to both Windows and Ubuntu environments.Streamlining Library Integration with CMakeCMake offers a robust mechanism for managing external libraries, simplifying the process of adding them to your C++ projects. Here are the fundamental approaches:      FetchContent Module: This convenient module assists in downloading and integrating libraries directly from source repositories. It’s ideal for libraries under active development or those not readily available through package managers.        find_package Command: For libraries distributed with package managers (e.g., PkgConfig, Conan, vcpkg, etc.), CMake’s find_package command simplifies the discovery and linking process.        Manual Configuration: In some cases, you might need to set environment variables or manually specify library and include directories. This approach is usually employed for libraries not managed by package managers.  Exploring Popular C++ Libraries:Now, let’s embark on a journey through integrating some of the most popular C++ libraries.Google TestPurpose: Google Test is a robust testing framework designed for writing unit tests in C++.Integration Google Test using FetchContentWindows and Ubuntu Instructions: The procedure for both systems is identical using CMake’s FetchContent.include(FetchContent)         # to use FetchContent_Declare# -- START: GOOGLE_TEST_INCLUDE --FetchContent_Declare(    googletest    GIT_REPOSITORY https://github.com/google/googletest.git    GIT_TAG main    OVERRIDE_FIND_PACKAGE)FetchContent_MakeAvailable(googletest)include(GoogleTest)         # to use gtest_discover_teststarget_link_libraries(simple_test GTest::gtest_main)# -- END: GOOGLE_TEST_INCLUDE --# test filesadd_executable(simple_test \"simple_test.cpp\")gtest_discover_tests(simple_test)Simple Test Code: simple_test.cpp# include &lt;gtest/gtest.h&gt;TEST(HelloTest, BasicAssertions) {    // Expect two strings not to be equal.    EXPECT_STRNE(\"hello\", \"world\");    // Expect equality.    EXPECT_EQ(7 * 6, 42);}Installing Google Test on UbuntuFor Ubuntu, you can alternatively install Google Test using apt:sudo apt-get install libgtest-devThen manually compile the library and link it to your project.Google BenchmarkPurpose: Google Benchmark simplifies the process of benchmarking C++ code for performance testing.Integration Google Benchmark using FetchContentinclude(FetchContent)   # to use FetchContent_Declare# -- START: GOOGLE_BENCHMARK_INCLUDE --FetchContent_Declare(    googlebenchmark    GIT_REPOSITORY https://github.com/google/benchmark.git    GIT_TAG main    OVERRIDE_FIND_PACKAGE)FetchContent_MakeAvailable(googlebenchmark)target_link_libraries(${EXE_NAME} benchmark::benchmark)# -- END: GOOGLE_BENCHMARK_INCLUDE --# test filesadd_executable(simple_benchmark \"simple_benchmark.cpp\")gtest_discover_tests(simple_benchmark)Example Benchmark Code: simple_benchmark.cpp#include &lt;benchmark/benchmark.h&gt;static void BM_StringCreation(benchmark::State&amp; state) {  for (auto _ : state)    std::string empty_string;}// Register the function as a benchmarkBENCHMARK(BM_StringCreation);static void BM_StringCopy(benchmark::State&amp; state) {  std::string x = \"hello\";  for (auto _ : state)    std::string copy(x);}BENCHMARK(BM_StringCopy);Installing Google Benchmark on Ubuntusudo apt-get install libbenchmark-devUpdate your CMake file:find_package(benchmark REQUIRED)target_link_libraries(MyBenchmarkTarget benchmark::benchmark)OpenCVPurpose: OpenCV is a powerful library for real-time computer vision and image processing.Integration of OpenCV on Windows  Download the pre-built OpenCV binaries for MinGW from the OpenCV-MinGW-Build.  Ensure you add the OpenCV binaries to your PATH variable.CMakeLists.txt:# Add thisset(OpenCV_DIR \"C:\\\\OpenCV-MinGW-Build-OpenCV-4.5.5-x64\")# Find and link OpenCVfind_package(OpenCV REQUIRED)target_include_directories(MyApp PRIVATE ${OpenCV_INCLUDE_DIRS})target_link_libraries(MyApp PRIVATE ${OpenCV_LIBS} )To avoid hard coded paths in CMake, you could consider adding OpenCV_DIR to your system’s PATH variable.Integration of OpenCV on UbuntuTo install OpenCV on Ubuntu:sudo apt-get install libopencv-devThen update your CMakeLists.txt:find_package(OpenCV REQUIRED)target_link_libraries(MyApp PRIVATE ${OpenCV_LIBS})Sample OpenCV Code: main.cpp#include &lt;opencv2/opencv.hpp&gt;int main(int argc, char *argv[]) {     // Create a window using OpenCV     cv::namedWindow(\"MyWindow\", cv::WINDOW_AUTOSIZE);     // Wait for a keystroke in the window     cv::waitKey(0);    return 0;}PkgFinder Package Manager  Purpose: A platform-independent package manager for C libraries.Integration of PkgFinder on Windows      Download and install the required binaries from the pkg-config website.Specifically, you’ll need to install the required binaries. Copy the following files into your MinGW64 bin directory:                  bin/pkg-config.exe from pkg-config_0.26-1_win32.zip                    bin/intl.dll from gettext-runtime_0.18.1.1-2_win32.zip                    bin/libglib-2.0-0.dll from glib_2.28.8-1_win32.zip                  Note that this is not necessary for CLion’s bundled CMake or for MSVC.  Installing on Ubuntusudo apt-get install pkg-configExample usage in CMakeLists.txtfind_package(PkgConfig REQUIRED)pkg_check_modules(LIBNAME REQUIRED libname)target_include_directories(MyApp PRIVATE ${LIBNAME_INCLUDE_DIRS})target_link_libraries(MyApp PRIVATE ${LIBNAME_LIBRARIES})GStreamer  Purpose: GStreamer is a powerful multimedia framework for streaming and video processing.Integration of GStreamer on WindowsGstream requires PkgFinder packe for CMakeTo use GStreamer in your C++ projects, ensure the following:      Make sure that Microsoft Visual C++ Redistributable is installed (or install it from the official website vc_redist.x86.exe)        Install the GStreamer runtime and SDK (MSVC-64 version) from GStreamer’s website.        Add the GStreamer’s binary folder to the system PATH variable.        Set the PKG_CONFIG_PATH environment variable to the GStreamer package config path: PKG_CONFIG_PATH = path/to/gstreamer/1.0/msvc_x86_64/lib/pkgconfig`  Update your CMakeLists.txt:find_package(PkgConfig REQUIRED)pkg_check_modules(GST REQUIRED gstreamer-1.0)pkg_search_module(GSTREAMER REQUIRED IMPORTED_TARGET gstreamer-1.0&gt;=1.4)target_include_directories(MyApp PRIVATE  ${GST_INCLUDE_DIRS})target_link_libraries(MyApp PRIVATE PkgConfig::GSTREAMER)Integration of GStreamer on UbuntuTo install GStreamer:sudo apt-get install gstreamer1.0-devCatch2Downloading and Installing Catch2Catch2 is another popular testing framework. To add Catch2 to your project, clone the repository and build it:git clone https://github.com/catchorg/Catch2.gitcd Catch2# if you want a specific versiongit checkout v2.13.9Build and install the library:mkdir build &amp;&amp; cd buildcmake .. -G \"MinGW Makefiles\"     # or \"Visual Studio 17 2022\" cmake --build . --config Release  # or Debugcmake --install . --prefix /path  # Path to installationBy following these instructions, you should be able to seamlessly integrate these libraries into your C++ projects using CMake.Qt6Purpose: Qt6 is a modern, cross-platform GUI framework for building high-performance, visually rich applications. Qt6 also includes non-GUI components, making it a comprehensive tool for application development.Integration of Qt6 on Windows  Firstly, install Qt from Qt’s official website  Integrating Qt6 in a self-sufficient manner with CMake involves properly setting up the environment and linking the necessary components.Setting Up CMake      At the project level, define the CMAKE_PREFIX_PATH to locate the Qt libraries:     # Paths to depedencies set(CMAKE_PREFIX_PATH      \"${DEPENDENCY_FOLDER}/some_library/\"      \"path/to/Qt/6.5.3/mingw_64/lib/cmake/Qt6\" )        At the executable/library level, include the following configurations:     find_package(Qt6 REQUIRED COMPONENTS Core Gui)     # Enable Qt's meta-object compiler (moc), resource compiler (rcc), and UI compiler (uic) set(CMAKE_AUTOMOC ON) set(CMAKE_AUTORCC ON) set(CMAKE_AUTOUIC ON)     # Define Qt version macros add_definitions(-DQT_VERSION_MAJOR=${Qt6_VERSION_MAJOR}) add_definitions(-DQT_VERSION_MINOR=${Qt6_VERSION_MINOR}) add_definitions(-DQT_VERSION_PATCH=${Qt6_VERSION_PATCH})        Next, add all what is dependent on MOC, RCC, UIC. and so on     add_executable(MyApp)     # Declare it as a GUI application (disable console) set_target_properties(MyApp PROPERTIES      WIN32_EXECUTABLE TRUE      MACOSX_BUNDLE TRUE )     # Link against Qt6 Components target_link_libraries(MyApp PRIVATE Qt6::Core Qt6::Gui)        Only then, set up the executable:     # Add sources and headers target_sources(experiment_01 PRIVATE      source/main.cpp      include/MyApp.h    # Also headers with QObject )     # Specify include directories target_include_directories(experiment_01 PRIVATE include)  Linking Libraries  For platform-specific libraries, copy the necessary plugins (e.g., qwindows.dll) to the platform directory in your binary.path/to/Qt/6.5.3/mingw_64/plugins/platformsIf you are on Windows, Copy qwindows.dll  Core Qt components such as Qt6Core.dll, Qt6Widgets.dll, and Qt6Gui.dll can be found in:path/to/Qt/6.5.3/mingw_64/binIntegration of Qt6 on UbuntuTo integrate Qt6 on Ubuntu, follow these steps:      Install Qt6: On Ubuntu, you can use the system’s package manager to install the necessary development packages for Qt6.     sudo apt-get install qt6-base-dev qt6-tools-dev-tools qt6-tools-dev qt6-base-dev-tools    This will install the Qt6 Core, Gui, and other essential components.        Set Up CMake for Qt6: Once Qt6 is installed, configure your CMakeLists.txt to find and link the necessary Qt6 components.  Deploying Qt6 Applications on UbuntuTo ensure your Qt6 application runs smoothly on Ubuntu, you might need to ensure that the correct Qt6 libraries and plugins are packaged with your application. For development purposes, the necessary libraries will usually be located automatically through CMake, but for deployment, you may need to package or point to the correct Qt paths manually.For Qt6 deployment, use the qt6-deploy tool, available as part of the Qt6 installation, to gather all the necessary components and bundle them with your application.qt6-deploy MyAppConclusionIn this guide, we have covered the essential steps to seamlessly integrate some of the most widely-used C++ libraries into your projects using CMake. From Google Test for unit testing, Google Benchmark for performance measurement, OpenCV for computer vision, to GStreamer for multimedia handling, and Qt6 for building cross-platform graphical applications, this guide provides a structured approach to handling dependencies."
  },
  
  {
    "title": "CMake - Installation On Windows",
    "url": "/posts/CMake-On-Windows/",
    "categories": "Software-Development, Cmake",
    "tags": "Software, C++, Cmake, Windows",
    "date": "2023-09-19 16:18:00 +0200",
    





    
    "snippet": "Here is a quick way to get started into development with CMake on Windows x64.Getting StartedDownloads  Download MinGW64 (posix, seh, msvcrt) from here.  Download CMake (Windows x64) from here.Inst...",
    "content": "Here is a quick way to get started into development with CMake on Windows x64.Getting StartedDownloads  Download MinGW64 (posix, seh, msvcrt) from here.  Download CMake (Windows x64) from here.Installation  Install CMake in C:\\Program Files\\Cmake.  Copy the minGW64 folder into C:\\.  Add the following binary paths to the PATH variable:          C:\\minGW64\\bin      C:\\Program Files\\Cmake\\bin      First Project  The simplest project to build is a Hello world program. Hence we will add a main.cpp source:#include &lt;iostream&gt;int main() {    std::cout &lt;&lt; \"Hello World!\\n\";    return 0;}  The corresponding cmake instruction would be the file CMakeLists.txt:cmake_minimum_required(VERSION 3.10)# Project Nameproject(HelloWorld)# Add an executable with sourcesadd_executable(    ${PROJECT_NAME} main.cpp)  To build the project now you should run the following commands# compilemkdir buildcd buildcmake .. -G \"MinGW Makefiles\"   # Makefile for minGWmingw32-make# cleancd ..rmdir /s /q buildMore  Check out the CMake Brief reference for an overview of the commands.  Check out how to integrate various C++ libraries.  Check out how to publish your own CMake Library professionally."
  },
  
  {
    "title": "CMake - Brief Reference",
    "url": "/posts/CMake-Brief-Reference/",
    "categories": "Software-Development, Cmake",
    "tags": "Software, C++, Cmake, Reference",
    "date": "2023-09-19 15:12:00 +0200",
    





    
    "snippet": "CMake is a powerful and flexible build system generator that supports the creation of makefiles, project files, and build environments across various platforms and compilers. Below is a brief refer...",
    "content": "CMake is a powerful and flexible build system generator that supports the creation of makefiles, project files, and build environments across various platforms and compilers. Below is a brief reference guide to some essential commands and patterns commonly used in CMake.Key Commands and ConceptsProject DefinitionCMake allows for detailed configuration of your project. Below are different levels of project definition:  Basic Project Definition: Defines the project name.project(MyProjectName)  Project with Versioning: Specifies the project name along with its version.project(MyProjectName VERSION 1.0.0)  Comprehensive Project Configuration: Provides additional details such as the languages used, a brief description, and a homepage URL.project(  MyProjectName   VERSION 1.0.0  LANGUAGES C CXX ASM Fortran CUDA  DESCRIPTION \"This is a sample project\"  HOMEPAGE_URL \"https://example.com\")VariablesVariables in CMake are fundamental for managing values and passing data throughout the CMakeLists.txt files.Definition  Basic Variable: Sets a variable with a specified value. Scoping can be controlled by specifying the parent scope.set(VARIABLE_NAME \"Value\")                  # local scopeset(VARIABLE_NAME \"Value\" PARENT_SCOPE)     # parent scope  List Variable: Commonly used for defining lists of source files.set(SOURCES main.cpp MyClass.cpp AnotherClass.cpp)Appending to Variables  Appending Values: Adds new values to an existing list.set(SOURCES ${SOURCES} YetAnotherClass.cpp) # Traditional waylist(APPEND SOURCES YetAnotherClass.cpp)    # using APPENDExecutable ConfigurationDefining and managing executables within your project can be easily achieved through CMake:  Basic Executable: Defines an executable from a single source file.add_executable(my_executable main.cpp)  Multiple Source Files: Creates an executable from multiple source files.add_executable(my_executable ${SOURCES})  Conditional Source Files: Dynamically adds source files based on platform or other conditions.if(WIN32)    list(APPEND SOURCES win_main.cpp)else()    list(APPEND SOURCES unix_main.cpp)endif()add_executable(my_app ${SOURCES})  Setting Executable Properties: Configures specific properties, such as the C++ standard required.add_executable(my_app main.cpp)set_target_properties(my_app PROPERTIES    CXX_STANDARD 11    CXX_STANDARD_REQUIRED YES    CXX_EXTENSIONS NO)Including DirectoriesCMake offers flexible methods to manage include directories, ensuring that the compiler can locate the necessary header files:  Global Include Directory: This approach sets include directories globally, but it is generally discouraged due to its potential to introduce conflicts.include_directories(${CMAKE_SOURCE_DIR}/include)    # bad practice  Target-Specific Include Directory: Specifies include directories for a specific target, promoting better encapsulation and avoiding global scope issues.add_executable(my_app main.cpp)target_include_directories(my_app PRIVATE ${CMAKE_SOURCE_DIR}/include)Library ManagementLibraries are crucial in C++ projects, and CMake provides robust commands for adding and linking libraries effectively:Adding Libraries  Static Library: Creates a static library from specified source files.add_library(my_static_lib STATIC src/lib.cpp)  Shared Library: Creates a shared library.add_library(my_shared_lib SHARED src/lib.cpp)  Module Library: Creates a library that is loaded dynamically at runtime.add_library(my_shared_lib MODULE src/lib.cpp)  Object Library: Compiles sources into object files without archiving or linking them into a library.add_library(my_shared_lib OBJECT src/lib.cpp)Linking Libraries  Linking to an Executable: Links a library to an executable.add_executable(my_app main.cpp)add_library(my_lib STATIC src/lib.cpp)target_link_libraries(my_app PRIVATE my_lib)  Linking System Libraries: Links against a system-provided library.find_library(MATH_LIB m)if(MATH_LIB)    target_link_libraries(my_app PRIVATE ${MATH_LIB})endif()  Importing External Libraries: Allows the use of an external library in your project.add_library(external_lib UNKNOWN IMPORTED)set_target_properties(external_lib PROPERTIES  IMPORTED_LOCATION \"/path/to/external_lib.a\"  INTERFACE_INCLUDE_DIRECTORIES \"/path/to/includes\")  Known Libraries: Examples of linking against some well-known libraries. (Examples for Threads, Catch2, OpenCV, Google Benchmark, and Eigen provided)Predefined Variables  CMAKE_SOURCE_DIR: The top-level source directory.message(\"Top-level source directory: ${CMAKE_SOURCE_DIR}\")  CMAKE_BINARY_DIR: The top-level build directory (usually the directory where you invoked CMake).message(\"Binary directory: ${CMAKE_BINARY_DIR}\")  CMAKE_CURRENT_SOURCE_DIR: The source directory of the current CMakeLists.txt.include(${CMAKE_CURRENT_SOURCE_DIR}/extra.cmake)  CMAKE_CURRENT_BINARY_DIR: The build directory corresponding to the current source directory.set(EXECUTABLE_OUTPUT_PATH ${CMAKE_CURRENT_BINARY_DIR}/bin)  CMAKE_PROJECT_NAME: The name of the first project set in the top-level CMakeLists.txt.message(\"Top level project: ${CMAKE_PROJECT_NAME}\")  CMAKE_CXX_COMPILER: The full path to the C++ compiler.message(\"Using compiler: ${CMAKE_CXX_COMPILER}\")  CMAKE_C_COMPILER: The full path to the C++ compiler.message(\"Using compiler: ${CMAKE_C_COMPILER}\")  CMAKE_PREFIX_PATH: Directories to be searched by find_package() before its default paths.list(APPEND CMAKE_PREFIX_PATH \"/custom/path\")InstallationCMake provides a flexible install() command that allows you to specify which files should be installed and where they should go. This is useful for deploying your project after it has been built.Basic Install CommandTo install a target, such as a library or an executable, you can use the install() command in your CMakeLists.txt:# Install an executableinstall(TARGETS my_executable DESTINATION bin)# Install a libraryinstall(TARGETS my_library        ARCHIVE DESTINATION lib        LIBRARY DESTINATION lib        RUNTIME DESTINATION bin)Installing Header FilesYou can also install header files using the install() command:install(FILES my_header.h DESTINATION include)Directory InstallationIf you have multiple header files in a directory, you can install them all at once:install(DIRECTORY include/ DESTINATION include)Full Installation ExampleHere’s an example that combines everything:project(MyProject)add_executable(my_executable main.cpp)add_library(my_library STATIC my_library.cpp)install(TARGETS my_executable my_library        RUNTIME DESTINATION bin        LIBRARY DESTINATION lib        ARCHIVE DESTINATION lib)install(FILES my_header.h DESTINATION include)install(DIRECTORY include/ DESTINATION include)Running the Install CommandTo install the targets and files as specified, you can run the following CMake command after building:cmake --install buildThis will copy the built executables, libraries, and header files to the directories specified in your install() commands.By understanding and utilizing these commands and best practices, developers can efficiently manage their C++ projects with CMake, ensuring scalability, maintainability, and cross-platform compatibility."
  },
  
  {
    "title": "The Black Pill (STM32F411CEU6)",
    "url": "/posts/BlackPill-STM32F411CEU6/",
    "categories": "Embedded-Development, STM32, STM32F411CEU6",
    "tags": "Embedded, STM32, blackpill, STM32F411CEU6, ARM, Cortex-m4",
    "date": "2023-05-17 13:41:00 +0200",
    





    
    "snippet": "              In this article, we will get you started with the STM32F411CE board (aka the black pill). For a complete overview of the board see this.    This chip is based on ARM Cortex-M4 32-Bit ...",
    "content": "              In this article, we will get you started with the STM32F411CE board (aka the black pill). For a complete overview of the board see this.    This chip is based on ARM Cortex-M4 32-Bit Architecture with clock frequency of 100 MHz RAM of 512KB.    This chip is manufactured by the Dutch company STMicroelectronics, which is based in Switzerland. The company provides several tools to develop for their chips. The official IDE is called the STM32CUBE IDE which is used for this quick tutorial.  Getting StartedOverviewThe illustration below demonstrates the characteristics of the pins on the board.Requirements      Development Environment: You can choose either of the following:          STM32Cube IDE:        This is the official STM32 IDE and it includes build environment. you can download it from here.                  CMake and Custom IDE:        Assuming you have CMake installed.                              Download the GNU Arm Embedded Toolchain from here and add it to PATH. This is important to compile the project.                                Download the OpenOCD from here and add it to PATH. This is important for debugging.                                Download the STM32CubeMX from here and add it to PATH. This is important to generate the project files along HAL library.                                    STM32 Cube Programmer: To upload the binary to the chip. You can download it from here.  Setting up the environmentSetting Up the ClockSet HSE and LSE to crystal clock on the RCC. Now we will configure the clock depending on the chip. For example, the STM32F411CEUx from Weact is connected to a $32.786$ kHz resonator on the LSE and a 25 MHz resonator on the HSE, so the configuration diagram should be like this:  Set PPL Source Mux to HSE  Set /M = / 25  Set *N = X 192  Set /Q = / 4  Set /P = / 2  Set System Clock Mux to PLLCLK  Set AHB Prescaler = / 1Notice that the STM32F411CEUx supports up to 100 MHz clocking, but since the Universal Serial Bus On-The-Go Full Speed (USB_OTG_FS) requires a dedicated 48 MHz clock (datasheet 3.27), the clock responsible for this (48 MHz clocks) comes from the Main PLL directly. By clocking the HCLK to 96 MHz, we can achieve a division that results in 48 MHz for this clock.Project StructureProject Settings (myproject.ioc)This file defines the settings of the chip when it starts, and the necessary code is re-generated whenever this file is updated. From here, you can set the initial mode of the pins (input. output, etc…), Direct Memory Access (DMA) settings, timers and more.Linker Script (STM32F411CEU6_FLASH.ld)Let’s take a look at the linker script generated by STM32 Cube MX:/* Entry Point */ENTRY(Reset_Handler)/* Highest address of the user mode stack */_estack = ORIGIN(RAM) + LENGTH(RAM);    /* end of RAM *//* Generate a link error if heap and stack don't fit into RAM */_Min_Heap_Size = 0x200;      /* required amount of heap  */_Min_Stack_Size = 0x400; /* required amount of stack *//* Specify the memory areas */MEMORY{RAM (xrw)      : ORIGIN = 0x20000000, LENGTH = 20KFLASH (rx)     : ORIGIN = 0x08000000, LENGTH = 64K}/* ... */In the linker script (STM32F411CEU6_FLASH.ld), the ENTRY(Reset_Handler) directive specifies this entry point.The Reset_Handler is the entry point for the program and is defined in the assembly file startup_stm32f103xb.s.  It is responsible for initializing the system and preparing the execution environment before jumping to the main application code.  When the microcontroller is reset, the Reset_Handler is the first function that gets executed as specified in the above linker.  This handler is crucial in setting up the system by configuring the stack pointer, initializing data segments, and calling the main() function.Memory LayoutThe memory configuration is defined in the linker script under the MEMORY section. This section specifies the start addresses and lengths of different memory regions in the microcontroller:  RAM: The RAM region is defined with a starting address of 0x20000000 and a length of 20KB. This is the area where the runtime data (variables, stack, and heap) will be stored.  FLASH: The FLASH region, starting at 0x08000000 with a length of 64KB, is used to store the program code and constants.Stack and Heap Configuration      _estack: The _estack symbol defines the highest address of the stack in RAM. It is calculated as the sum of the starting address of RAM (ORIGIN(RAM)) and the total length of RAM (LENGTH(RAM)).This ensures that the stack starts at the end of the available RAM space and grows downwards.        _Min_Heap_Size: This value specifies the minimum required heap size, which is set to 0x200 (512 bytes).The heap is used for dynamic memory allocation during runtime.        _Min_Stack_Size: This value defines the minimum required stack size, set to 0x400 (1024 bytes).The stack is used for storing local variables and function call information during execution.  These values ensure that the heap and stack have enough space within the RAM, preventing overlap and potential runtime errors. The linker script will generate an error if the specified heap and stack sizes do not fit within the defined RAM area.C Entry File (core/Src/main.c)This is the main source code, where the entry function resides. Also, this is place where most of the generated code done by the IDE is written after updating myproject.ioc.We will look into two important functions here.static void MX_GPIO_Init(void)This function sets up the initial settings for the IO pins of the chip. On the board the blue LED is connected to pin C13. If we set this pin mode to GPIO_Output mode in the myproject.ioc file, as in the illustration belowFigure 2: Configuring the chip’s pinswe can see that the IDE has generated the following code in the function MX_GPIO_Init:GPIO_InitTypeDef GPIO_InitStruct = {0};/* GPIO Ports Clock Enable */__HAL_RCC_GPIOC_CLK_ENABLE();/*Configure GPIO pin Output Level */HAL_GPIO_WritePin(GPIOC, GPIO_PIN_13, GPIO_PIN_RESET);/*Configure GPIO pin : PC13 */GPIO_InitStruct.Pin = GPIO_PIN_13;GPIO_InitStruct.Mode = GPIO_MODE_OUTPUT_PP;GPIO_InitStruct.Pull = GPIO_NOPULL;GPIO_InitStruct.Speed = GPIO_SPEED_FREQ_LOW;HAL_GPIO_Init(GPIOC, &amp;GPIO_InitStruct);Lines from 9 to 14 are responsible for initializing the pin C13. We can see in line that the HAL library provides the function HAL_GPIO_Init which takes first the name of the Pins block and then a pointer to a structure GPIO_InitTypeDef. This is also how the pin settings is changed programmatically. The details of the pins settings are explained in the following section.The Pull variable specifies which resistors should be connected to the pin. The possible configurations are  Pull down (GPIO_PULLDOWN)  Pull up (GPIO_PULLUP)  No resistor (GPIO_NOPULL)The pull down resistor connects the pin to the ground, while the pull up resistor connects the pin to 3.3V.Uploading FirmwareUploading firmware to an STM32 microcontroller can be achieved using different interfaces such as DFU (Device Firmware Upgrade) or UART. Below are the steps for using both methods with the WeAct Black Pill board.Using DFU ModeTo upload the firmware via DFU mode, connect your device via USB and use the following command:STM32_Programmer_CLI -c port=usb1 -w \\Debug\\app.bin 0x08000000  port=usb1: Specifies the USB port.  -w \\Debug\\app.bin: Indicates the path to the binary file.  0x08000000: Specifies the start address in the flash memory.Using UARTTo upload the firmware via UART, use the following command:STM32_Programmer_CLI -c port=COM10 -w \\Debug\\app.elf  port=COM10: Specifies the COM port.  -w \\Debug\\app.elf: Indicates the path to the ELF file.To reset and disable the read protection of the microcontroller, you can use:STM32_Programmer_CLI -c port=COM10 -rduWorking with GPIOsGPIO (General Purpose Input/Output) is crucial for interfacing with the STM32 microcontroller’s pins. Below is an overview of how to configure and use GPIOs.GPIO Initialization (GPIO_InitTypeDef)GPIO_InitTypeDef is a structure used to define the specifications of a GPIO pin. Below are the key fields in this structure:typedef struct  {    uint32_t Pin;  uint32_t Mode  uint32_t Pull;  uint32_t Speed;    uint32_t Alternate; // Only available in &gt;= Cortex-M4} GPIO_InitTypeDef;      Pin: Specifies the GPIO pins to be configured. Multiple pins can be selected using a bitwise OR operation. Example: (GPIO_PIN_0 | GPIO_PIN_1).  Mask of the pin, (GPIO_PIN_0 = 0x0001), (GPIO_PIN_1 = 0x0002)…    Mode: Defines the operating mode for the selected pins. The following modes are available:          Input Mode                  GPIO_MODE_INPUT: Input Floating Mode                          The input mode changes a variable variable according to the voltage applied to the pin (Note this should never exceed 3.3V for most pins).                                          Output Mode                  GPIO_MODE_OUTPUT_PP: Output Push-Pull                          The push-pull mode sets up the pin for a single direction output. The pin state, can either be high or low.                                GPIO_MODE_OUTPUT_OD: Output Open Drain                          The open-drain mode, sets up the pin to accept bidirectional input and output. (For more see this article).                                          Alternate Function                  GPIO_MODE_AF_PP: Push-Pull          GPIO_MODE_AF_OD: Open Drain                    Analog Mode                  GPIO_MODE_ANALOG: Analog Mode                          The analog mode allows the pin to read the voltage applied to it. However, not all pins are able to be set to this mode, in the case of this chip, these pins are A0..A7 as well as B0 and B1, which also correspond to ADC0..ADC9.Accessing the analog value read from the pin needs additional configuration, such as direct memory access (DMA), which we will look into in the following sections.                                          External Interrupt                  GPIO_MODE_IT_RISING: Rising Edge          GPIO_MODE_IT_FALLING: Falling Edge          GPIO_MODE_IT_RISING_FALLING: Rising and Falling Edge                    External Event                  GPIO_MODE_EVT_RISING: Rising Edge          GPIO_MODE_EVT_FALLING: Falling Edge          GPIO_MODE_EVT_RISING_FALLING: Rising and Falling Edge                      Pull: Specifies the internal pull-up or pull-down resistor activation:          GPIO_NOPULL: No pull-up or pull-down activation.      GPIO_PULLUP: Pull-up resistor activation.      GPIO_PULLDOWN: Pull-down resistor activation.        Speed: Defines the speed for the GPIO pin:          GPIO_SPEED_FREQ_LOW: 2 MHz.      GPIO_SPEED_FREQ_MEDIUM: 12.5 to 50 MHz.      GPIO_SPEED_FREQ_HIGH: 25 to 100 MHz.      GPIO_SPEED_FREQ_VERY_HIGH: 50 to 200 MHz.      An example of initializing a pin:GPIO_InitTypeDef GPIO_InitStruct = {};GPIO_InitStruct.Pin = GPIO_PIN_13;  GPIO_InitStruct.Mode = GPIO_MODE_OUTPUT_PP;  GPIO_InitStruct.Pull = GPIO_NOPULL;  GPIO_InitStruct.Speed = GPIO_SPEED_FREQ_LOW;  HAL_GPIO_Init(GPIOC, &amp;GPIO_InitStruct);GPIO Pin States (GPIO_PinState)A GPIO pin can be in one of the following two states:  Reset State (GPIO_PIN_RESET): Logical low (0).  Set State (GPIO_PIN_SET): Logical high (1).Writing to a PinTo set or reset a GPIO pin, you can use the following methods:Setting a PinGPIOA -&gt; BSSR = GPIO_PIN_0;                         // fastGPIOA -&gt; ODR |= GPIO_PIN_0;                         // legacyHAL_GPIO_WritePin(GPIOA, GPIO_PIN_0, GPIO_PIN_SET); // HAL LibraryResetting a PinGPIOA -&gt; BSSR = (uint32_t)GPIO_PIN_0  &lt;&lt; 16U;         // fastGPIOA -&gt; ODR &amp;= ~GPIO_PIN_0;                          // legacyHAL_GPIO_WritePin(GPIOA, GPIO_PIN_0, GPIO_PIN_RESET); // HAL LibraryNo Masking needed for setting/resetting a pin when using BSRR register, ODR Registers stores the output values and we can use it to read the output values.Note that the function HAL_GPIO_WritePin writes the value to the pin atomically without OR’ing it with other masks. That means interrupts do not have to be disabled.Reading a PinJust like reading the Output data from ODR, we can read the input data from IDR.uint8_t PA0;PA0 = GPIOA -&gt; IDT &amp; GPIO_PIN_0;            // legacyPA0 = HAL_GPIO_ReadPin(GPIOA, GPIO_PIN_0);  // HAL LibraryGPIO Port Configuration (GPIO_TypeDef)Each GPIO port is represented by a GPIO_TypeDef structure, which contains the following registers:typedef struct  {    __IO uint32_t MODER;   // Mode Register  __IO uint32_t OTYPER;  // Output Type Register  __IO uint32_t OSPEEDR  // Output Speed Register  __IO uint32_t PUPDR    // Pull-Up Pull-Down Register  __IO uint32_t IDR;     // Input Data Register  __IO uint32_t ODR;     // Output Data Rigister  __IO uint32_t BSRR     // Bit Set/Reset Register  __IO uint32_t LCKR;    // Lock Register  __IO uint32_t AFR[2];  // Alternate Function Registers} GPIO_TypeDef;  MODER: Port Mode Register (offset 0x00).          Each pin has 2 bits in this register:              00: Input mode        01: General-purpose output mode        10: Alternate function mode (like UART, SPI, etc.)        11: Analog mode              OTYPER: Port Output Type Register (offset 0x04).          Output Type              0: Output push-pull (default)        1: Output open-drain              OSPEEDR: Port Output Speed Register (offset 0x08).          Each pin has 2 bits in this register:              00: Low speed        01: Medium speed        10: High speed        11: Very high speed              PUPDR: Port Pull-up/Pull-down Register (offset 0x0C).          Each pin has 2 bits in this register:              00: No pull-up, pull-down        01: Pull-up        10: Pull-down        11: Reserved              IDR: Input Data Register (offset 0x10).  ODR: Output Data Register (offset 0x14).  BSRR: Port Bit Set/Reset Register (offset 0x18).          This 32-bit register allows atomic bit-wise operations to set or reset individual bits in the ODR:              The lower 16 bits (0-15) are used to set the corresponding ODR bits.            // Set Pin A0GPIOA-&gt;BSRR = GPIO_PIN_0;              The upper 16 bits (16-31) are used to reset the corresponding ODR bits.            // Reset Pin A0GPIOA -&gt; BSSR = (uint32_t)GPIO_PIN_0 &lt;&lt; 16U;        LCKR: Port Configuration Lock Register (offset 0x1C).          This 16-bit register locks the configuration of the GPIO port to prevent accidental changes              Once locked, the configuration of the GPIO cannot be modified until the next reset.            // Step 1: Write the pin's lock pattern and set LCKK bitGPIOA-&gt;LCKR = GPIO_LCKR_LCKK | GPIO_PIN_0;// Step 2: Write the pin's lock pattern without LCKK bitGPIOA-&gt;LCKR = GPIO_PIN_0;// Step 3: Write the pin's lock pattern with LCKK bit againGPIOA-&gt;LCKR = GPIO_LCKR_LCKK | GPIO_PIN_0;// Step 4: Read LCKR to complete the lock sequenceuint32_t temp = GPIOA-&gt;LCKR;// The pin is now locked, and the configuration cannot be changed until a reset occurs        AFR[2]: Alternate Function Registers (offset 0x20, 0x24).In the following, we will at some of these registersGPIO Port Bit Set/Reset Register (BSRR)This register is used to atomically write to an output pin. It is used this wayGPIOA -&gt; BSSR = (uint32_t)GPIO_PIN_0 &lt;&lt; 16U;But this is exactly what HAL libary’s function HAL_GPIO_WritePin does. Hence, there is no need to access it directly for most cases.Pulse-Width-Modulation (PWM)Configuring PWM on the STM32 platform using STM32CubeIDE is a streamlined process. Beginning with the project’s configuration file, _myproject.ioc_, follow these steps:System Core Configuration      Clock Configuration: Navigate to System Core &gt; RCC. Set both the High-Speed Clock (HCLK) and Low-Speed Clock (LCLK) sources to Crystal/Ceramic Resonator. This ensures stable and accurate clocking for the timer peripherals.        Timer Configuration: Go to Timers &gt; TIM3. The TIM3 peripheral has four channels, each capable of generating PWM signals. For this example, activate Channel 1 by setting it to PWM Generation CH1, optionally the same for channel 2.  PWM Frequency and Duty Cycle CalculationThe PWM signal’s frequency is governed by the following equation:\\[f_\\text{PWM} =\\frac{f_\\text{APB Timer Clock}}{(ARR+1) \\cdot (PSC+1)}\\]  ARR (Auto-Reload Register): Defines the maximum count value before the timer resets.  PSC (Prescaler): Divides the timer clock frequency to adjust the PWM period.Both ARR and PSC registers hold values that are decremented by one from their actual count (i.e., an ARR value of 999 sets the period to 1000 counts).The duty cycle of the PWM signal is determined by the following relationship:\\[f_\\text{Duty}= \\frac{CCR}{ARR} [\\%]\\]  CCR (Capture Compare Register): Controls the pulse width of the PWM signal, directly influencing the duty cycle.These register values can be configured through the “Parameter Settings” window in STM32CubeIDE.Timer Initialization and ConfigurationOnce the parameters are set in the .ioc file, STM32CubeIDE generates a private variable htim3 in the main.c file. This variable is an instance of the TIM_HandleTypeDef structure, which manages and configures the timer.This generates a private variable htim3 in main.c. This is the handler of the timer./* Private variables */  TIM_HandleTypeDef htim3;TIM_HandleTypeDef Structure Overview:typedef struct {  TIM_TypeDef* Instance;      // Points to the TIMx peripheral (e.g., TIM1, TIM2).  TIM_Base_InitTypeDef init;  // Configuration parameters for the time base.  HAL_TIM_ActiveChannel;      // Channel  DMA_HandleTypeDef* hdma[7]; // DMA Handlers array  HAL_LockTypeDef;            // Locking Object  HAL_TIM_StateTypeDef;       // State} TIM_HandleTypeDef;Timer Initialization Function:The MX_TIM3_Init() function is responsible for initializing the TIM3 peripheral with the desired settings:static void MX_TIM3_Init() {    // Initialize the TIM3 peripheral handle    htim3.Instance = TIM3;      htim3.Init.Prescaler = 0;      htim3.Init.CounterMode = TIM_COUNTERMODE_UP;    htim3.Init.Period = 65535;      htim3.Init.ClockDivision = TIM_CLOCKDIVISION_DIV1;      htim3.Init.AutoReloadPreload = TIM_AUTORELOAD_PRELOAD_DISABLE;      // Initialize the timer for PWM operation    if (HAL_TIM_PWM_Init(&amp;htim3) != HAL_OK) Error_Handler();     // Configure the master configuration for synchronization    TIM_MasterConfigTypeDef sMasterConfig = {};      sMasterConfig.MasterOutputTrigger = TIM_TRGO_RESET;      sMasterConfig.MasterSlaveMode = TIM_MASTERSLAVEMODE_DISABLE;      // Apply the master configuration settings    if (HAL_TIMEx_MasterConfigSynchronization(&amp;htim3, &amp;sMasterConfig) != HAL_OK) Error_Handler();     // Configure the output compare (OC) settings for PWM on channel 1 and 2    TIM_OC_InitTypeDef sConfigOC = {0};      sConfigOC.OCMode = TIM_OCMODE_PWM1;      sConfigOC.Pulse = 0;      sConfigOC.OCPolarity = TIM_OCPOLARITY_HIGH;      sConfigOC.OCFastMode = TIM_OCFAST_DISABLE;    // Configure PWM channel 1 with the above settings    if (HAL_TIM_PWM_ConfigChannel(&amp;htim3, &amp;sConfigOC, TIM_CHANNEL_1) != HAL_OK) Error_Handler();     // Configure PWM channel 2 with the above settings    if (HAL_TIM_PWM_ConfigChannel(&amp;htim3, &amp;sConfigOC, TIM_CHANNEL_2) != HAL_OK) Error_Handler();      // Call post-initialization function to configure GPIO and other settings    HAL_TIM_MspPostInit(&amp;htim3);}Starting PWM OutputTo begin PWM signal generation on the configured channels, the following function calls are necessary within the main() function:  int main(void)  {    /* ... */        // Start PWM on Channel 1     if (HAL_TIM_PWM_Start(&amp;htim3, TIM_CHANNEL_1) != HAL_OK) Error_Handler();         // Start PWM on Channel 2    if (HAL_TIM_PWM_Start(&amp;htim3, TIM_CHANNEL_2) != HAL_OK) Error_Handler();        /* ... */}These function calls initiate PWM generation on the specified channels, allowing the microcontroller to output the configured PWM signals.TimersGeneral-purpose timers on the STM32 are highly versatile and can be used for a variety of timing tasks. Below are the steps to configure a general-purpose timer (e.g., TIM2) and set up an interrupt-based event handler.Timer Configuration      Set Clock Source: In STM32CubeIDE, set the clock source of TIM2 to Internal Clock to use the system clock as the timer’s clock source.        Set Counter Period and Prescaler: Configure the Counter Period (ARR) and Prescaler (PSC) values to achieve the desired timer frequency:    \\[ f_\\text{PWM} =\\frac{f_\\text{Clock Frequency}}{(ARR-1) \\cdot (PSC-1)} \\]    This equation determines the frequency at which the timer overflows and triggers an interrupt or updates its count.        Enable Auto-Reload Preload: Enable the Auto-Reload Preload to ensure that the counter resets seamlessly upon reaching the ARR value.  Initialization and Interrupt ConfigurationTo initialize the timer and configure it for interrupt generation, include the following code in your initialization function:static void MX_TIM2_Init(void) {    // Initialize TIM2    htim2.Instance = TIM2;      // Set prescaler to divide clock by 9600 (96 MHz / 9600 = 10 kHz)    htim2.Init.Prescaler = 9599;      htim2.Init.CounterMode = TIM_COUNTERMODE_UP;    // Set period for 1 Hz frequency (10 kHz / 10000 = 1 Hz)    htim2.Init.Period = 9999;    htim2.Init.ClockDivision = TIM_CLOCKDIVISION_DIV1;    htim2.Init.AutoReloadPreload = TIM_AUTORELOAD_PRELOAD_ENABLE;  // Enable auto-reload preload        // Initialize the timer    if (HAL_TIM_Base_Init(&amp;htim2) != HAL_OK) Error_Handler();        // Start the timer with interrupt enabled    if (HAL_TIM_Base_Start_IT(&amp;htim2) != HAL_OK) Error_Handler(); }Handling Timer InterruptsTo handle timer interrupts, define the interrupt callback function:void HAL_TIM_PeriodElapsedCallback(TIM_HandleTypeDef *htim) {    // Check if the interrupt is from TIM2    if (htim-&gt;Instance == TIM2) {        // Toggle an LED on GPIO pin PC13 as an example        HAL_GPIO_TogglePin(GPIOC, GPIO_PIN_13);      }}This function is called whenever the timer reaches its period value and generates an interrupt, allowing you to execute time-based tasks, such as toggling an LED or triggering other events.USB Serial Communication SetupIn this section, we will detail the setup and configuration of the Universal Serial Bus On-The-Go Full Speed (USB OTG FS) interface on the STM32 platform, which is compliant with the USB 2.0 standard. This interface is crucial for enabling USB communication, requiring a dedicated 48 MHz clock sourced from the High-Speed External (HSE) oscillator, as specified in the device’s datasheet (refer to section 3.27).Configuring the USB OTG FS ClockTo ensure the USB_OTG_FS peripheral operates correctly, it must be supplied with a precise 48 MHz clock, derived from the High-Speed External (HSE) oscillator. This clock configuration is critical for maintaining the timing requirements stipulated by the USB 2.0 standard.Step-by-Step Clock Setup      Activate the HSE and LSE Oscillators:          Begin by configuring the RCC (Reset and Clock Control) settings in STM32CubeMX. Set both the High-Speed External (HSE) and Low-Speed External (LSE) clocks to use crystal oscillators, which offer superior stability compared to internal RC oscillators.            Configure the PLL (Phase-Locked Loop):                  The main PLL should be configured to generate a system clock that is a multiple of 48 MHz. For instance, if your application allows, you might set the HCLK (High-speed Clock) to 96 MHz, which can then be divided by two to achieve the required 48 MHz for the USB peripheral.                    Example for STM32F411CEUx: This microcontroller typically uses a 25 MHz HSE and a 32.786 kHz LSE. Set the PLL to multiply the HSE to achieve a 96 MHz system clock, which can then be divided down to provide the 48 MHz USB clock directly from the Main PLL.                    Diagram Reference: The clock tree configuration should be adjusted accordingly to ensure the USB_OTG_FS peripheral is fed the correct 48 MHz signal, as visualized below.            Figure 1: Clock Configuration for USB_OTG_FSUSB Peripheral Configuration in STM32CubeMXAfter ensuring the clock is properly configured, proceed with setting up the USB OTG FS peripheral to handle USB communication at the hardware level.Detailed Configuration Steps      Enable USB OTG FS:          Within STM32CubeMX, navigate to Connectivity and select USB_OTG_FS.      Set the mode to Device Only, as this will configure the STM32 to act as a USB device when connected to a host system such as a PC.            Set Up the USB Device Middleware:                  Under Middleware, select USB_DEVICE. For serial communication over USB, choose the Communication Device Class (CDC), commonly referred to as Virtual COM Port. This selection enables the microcontroller to communicate with a host as if it were a standard serial port.                    Customize the USB device descriptors (such as the PRODUCT_String) within the Device Descriptor settings. These descriptors define how the USB device is identified by the host system, allowing for easier recognition and differentiation.                    Note: The USB_DEVICE middleware operates in conjunction with the STM32_USB_DEVICE_Library, which houses the core USB functionality, referred to as usb_core. The core library manages fundamental USB operations but delegates higher-level communication protocols to other modules.            Memory Management: Adjusting the Heap SizeTo ensure the microcontroller can handle USB communication efficiently, particularly when dealing with data buffers, it is necessary to adjust the default heap size.Heap Size Adjustment      Increase Heap Size:                  Access the Project Manager tab in STM32CubeMX. By default, the heap size may be set to 0x200 (512 bytes), which is often insufficient for USB operations.                    Increase the heap size to 0x600 (1536 bytes). This additional memory allocation is crucial for accommodating the buffers required by the USB communication stack, ensuring smooth data transmission and reception.            To ensure the heap size has increased we can look at the linker script/* Entry Point */ENTRY(Reset_Handler)/* Highest address of the user mode stack */_estack = ORIGIN(RAM) + LENGTH(RAM);    /* End of RAM *//* Define heap and stack sizes */_Min_Heap_Size = 0x600;      /* Required amount of heap (1.5KB) */_Min_Stack_Size = 0x400;     /* Required amount of stack (1KB) *//* Specify the memory areas */MEMORY{  RAM (xrw)      : ORIGIN = 0x20000000, LENGTH = 128K  FLASH (rx)     : ORIGIN = 0x08000000, LENGTH = 512K}  Heap Size: Updated to 0x600 (1536 bytes) to ensure sufficient memory for USB operations.  Stack Size: Maintained at 0x400 (1024 bytes) to support typical stack usage scenarios.Customizing USB Communication in usbd_cdc_if.cTo ensure that the device and the host computer agree on communication parameters such as baud rate, parity, and stop bits, the usbd_cdc_if.c file must be modified. This file also handles the reception of data from the USB interface.Modifying Line Coding Commands      Storing Line Coding Information:          To handle the Line Coding commands, add a variable of type USBD_CDC_LineCodingTypeDef to store the communication settings.        In the block for adding private variables (PV):     /* USER CODE BEGIN PV */ /* Private variables ---------------------------------------------------------*/ USBD_CDC_LineCodingTypeDef LineCoding; /* USER CODE END PV */        Handling SET and GET Line Coding Requests:          Modify the CDC_Control_FS function to handle CDC_SET_LINE_CODING and CDC_GET_LINE_CODING requests. This ensures the device correctly receives and responds to the host’s communication settings.         case CDC_SET_LINE_CODING:     LineCoding.bitrate =      (uint32_t)((pbuf[0]) | (pbuf[1] &lt;&lt; 8) | (pbuf[2] &lt;&lt; 16) | (pbuf[3] &lt;&lt; 24));     LineCoding.format = pbuf[4];     LineCoding.paritytype = pbuf[5];     LineCoding.datatype = pbuf[6]; break; case CDC_GET_LINE_CODING:     pbuf[0] = (uint8_t)(LineCoding.bitrate);     pbuf[1] = (uint8_t)(LineCoding.bitrate &gt;&gt; 8);     pbuf[2] = (uint8_t)(LineCoding.bitrate &gt;&gt; 16);     pbuf[3] = (uint8_t)(LineCoding.bitrate &gt;&gt; 24);     pbuf[4] = LineCoding.format;     pbuf[5] = LineCoding.paritytype;     pbuf[6] = LineCoding.datatype; break;          This implementation ensures that both the computer and the device agree on the communication parameters.      Handling Data Reception      Creating a Hook for Data Reception:          Define a weak function CDC_Receive_Handler that can be overridden to handle incoming data. This provides flexibility by allowing custom data handling outside of the default library implementation.        In the block for private function declarations:          A weak function is only compiled if implemented; otherwise, all calls to it are ignored, which helps avoid unnecessary code execution.         __weak void CDC_Receive_Handler(uint8_t* pbuf, uint32_t *Len);        Modifying CDC_Receive_FS Function:          Modify the CDC_Receive_FS function to call the CDC_Receive_Handler whenever data is received. This ensures that received data is processed as soon as it arrives.         static int8_t CDC_Receive_FS(uint8_t* Buf, uint32_t *Len) {   /* USER CODE BEGIN 6 */   USBD_CDC_SetRxBuffer(&amp;hUsbDeviceFS, &amp;Buf[0]);   USBD_CDC_ReceivePacket(&amp;hUsbDeviceFS);   CDC_Receive_Handler(Buf, Len);   /* &lt;-- added here */   return (USBD_OK);   /* USER CODE END 6 */ }          This function must execute quickly to ensure that the USB interface can continue processing incoming data without delays.      Finalizing the USB Communication SetupOnce the clock and peripheral configurations are complete, and the project code is generated by STM32CubeMX, the final step involves refining the generated code to suit your application’s specific needs.Code Customization      Generated Code Overview:          STM32CubeMX will generate several key files, including usb_device.c, usbd_desc.c, and usb_cdc_if.c. These files contain the foundational code for USB communication, including initialization routines and descriptor settings.            Editing usb_cdc_if.c:                  The file usb_cdc_if.c is where the core data handling functions are implemented. This is the primary location for customizing how data is sent and received over USB. Modify these functions to align with your application’s communication protocol and data handling requirements.                    Middleware Structure:                  usb_device.c: Manages the core USB device functionality.          usbd_desc.c: Contains the USB device descriptors, which define how the device appears to the host.          usb_cdc_if.c: Implements the interface for the CDC class, handling data transfers between the microcontroller and the USB host.                    By carefully following these steps, you will configure a robust and efficient USB communication interface on your STM32 microcontroller. The process involves precise clock setup, enabling and configuring the appropriate peripherals, adjusting memory allocations, and customizing the generated code to meet your application’s specific needs. This comprehensive approach ensures reliable and high-performance USB communication, suitable for a wide range of embedded applications.Configuring Analog Channels on STM32Setting up analog channels on the STM32 microcontroller involves several key steps, particularly when configuring the ADC (Analog-to-Digital Converter) to read analog signals. This section will guide you through the process of declaring pins as analog inputs, configuring the ADC for optimal performance, and utilizing internal references such as the temperature sensor and voltage reference.Selecting Analog Input PinsBefore proceeding with the configuration, it’s essential to identify which pins you will declare as analog inputs. This decision is crucial because changing the configuration later can be complex and may require reworking the hardware setup or significant software adjustments.ADC ConfigurationThe ADC peripheral in STM32 microcontrollers is highly versatile, capable of converting multiple analog inputs simultaneously using DMA (Direct Memory Access) for efficient data handling. The following steps outline the configuration process:      Selecting ADC Channels (ADCx):          Input Channels (INx): Choose the specific analog pins (INx) you intend to use as input channels. Each INx corresponds to a physical pin on the microcontroller.      Internal Channels: Additionally, you can select internal channels such as the temperature sensor and the internal voltage reference (Vrefint), which are invaluable for monitoring the microcontroller’s operating conditions.            Configuring DMA Settings:          DMA Channel: Add ADC1 to the DMA settings. This will allow the ADC to transfer conversion results directly to memory without CPU intervention.      Data Width: Set the data width to “WORD” to ensure that each conversion result is stored in a 32-bit word format.      Mode: Enable “Circular” mode for DMA. This mode allows continuous ADC conversions, where the DMA automatically restarts after each full transfer, ideal for real-time data acquisition.            Adjusting ADC Parameters:          Continuous Conversion Mode: Enable this mode to allow the ADC to continuously convert the selected channels without requiring additional triggers.      DMA Continuous Request: Enable this to keep the DMA in sync with the continuous ADC conversions, ensuring that each conversion result is automatically transferred to memory.      Number of Conversions: Set this parameter to the number of channels you have configured. This determines how many conversions the ADC performs before resetting.      Clock Prescaler: Set the prescaler to divide PCLK2 by 4. Given our configuration with a PCLK2 of 96 MHz, this results in an ADC clock of 24 MHz.      Sampling Time Calculation: To determine the conversion time, divide the number of cycles by the ADC clock. For example:                  3 Cycles: 324 MHz=0.125 microseconds\\frac{3}{24 \\text{ MHz}} = 0.125 \\text{ microseconds}24 MHz3​=0.125 microseconds. This is extremely fast and might not be suitable for accurate conversions.          480 Cycles: 48024 MHz=20 microseconds\\frac{480}{24 \\text{ MHz}} = 20 \\text{ microseconds}24 MHz480​=20 microseconds. This is a more reasonable time, balancing speed and accuracy for most applications.                          Implementing the ADC in the Main Program:          After configuring the ADC, a handle (hadc1) will be available in your main program. To store the ADC conversion results, declare a buffer:         uint32_t pData[2] = {0};  // Buffer to hold ADC conversion results          Start the ADC with DMA to begin storing conversion results in the buffer:         HAL_ADC_Start_DMA(&amp;hadc1, pData, 2);  // Start ADC with DMA, storing results in pData  Internal Voltage Reference (Vrefint)The STM32 microcontrollers include an internal voltage reference (Vrefint), which is particularly useful for compensating for power supply variations or for calibrating measurements. According to the STM32 datasheet (Section 6.3.23), the typical value of Vrefint is 1.21V. You can use this reference to calculate the actual voltage of an input pin as follows:voltage = value_pinA0 * 1210 / value_Vrefint;  // Calculate voltage in mVThis formula assumes that value_pinA0 is the ADC reading of the target pin, and value_Vrefint is the ADC reading of Vrefint. The result gives you the pin voltage in millivolts.Utilizing the Internal Temperature SensorThe internal temperature sensor in STM32 microcontrollers is useful for monitoring the temperature of the microcontroller itself, which can be an indicator of ambient temperature or the device’s thermal performance. However, note that the sensor primarily measures the temperature of the silicon die, which may not reflect rapid ambient temperature changes due to the sensor’s thermal inertia.Calculating TemperatureThe temperature can be calculated using the following formula derived from the sensor’s characteristics:\\[T= \\frac{V_\\text{temp} - V_{25}}{ \\text{slope}} + 25\\]Where:  VtempV_{temp}Vtemp​ is the ADC reading of the temperature sensor.  V25V_{25}V25​ is the voltage corresponding to 25°C, typically 0.76V (as per Section 6.3.21 of the datasheet).  The slope is the change in voltage per degree Celsius.To implement this in code, assuming you are working in millivolts, the formula can be expressed as:temp = ((V_temp * 3300) / 4095 - 760) * 1000 / slope + 25;For the STM32, where the slope might be around 2.5 mV/°C, you could simplify this further:temp = ((V_temp * 33000) / 4095 - 7600 + 25000) / 25;This calculation yields the temperature in degrees Celsius, adjusting for the reference voltage and typical sensor characteristics."
  }
  
]

